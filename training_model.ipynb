{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import json\n",
    "    import os\n",
    "    \n",
    "    import pandas as  pd\n",
    "    import spacy\n",
    "    \n",
    "    import seaborn as sns\n",
    "    import string\n",
    "\n",
    "    from tqdm import tqdm\n",
    "    from textblob import TextBlob\n",
    "    \n",
    "    from nltk.corpus import stopwords\n",
    "    import nltk\n",
    "    from nltk.stem import WordNetLemmatizer\n",
    "    from nltk import word_tokenize\n",
    "    import re\n",
    "    \n",
    "    \n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    from sklearn.feature_extraction.text import CountVectorizer\n",
    "    from sklearn.feature_extraction.text import TfidfTransformer\n",
    "    from sklearn.naive_bayes import MultinomialNB\n",
    "    from sklearn.pipeline import Pipeline\n",
    "    \n",
    "    \n",
    "    from sklearn.preprocessing import FunctionTransformer\n",
    "    from sklearn.base import BaseEstimator, TransformerMixin\n",
    "    from sklearn.pipeline import FeatureUnion\n",
    "    from sklearn.feature_extraction import DictVectorizer\n",
    "    \n",
    "    import swifter\n",
    "    \n",
    "    tqdm.pandas()\n",
    "except Exception as e:\n",
    "    print(\"Error : {} \".format(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "flight_rasp = pd.read_csv(\"flight_rasp_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_table = pd.read_csv(\"final_table_v2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "flight_rasp = flight_rasp.join(final_table['sum_bsm'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "flight_rasp_v2 = flight_rasp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "flight_rasp_v2['t_st'] = pd.to_datetime(flight_rasp_v2['t_st'], \n",
    "format = '%Y-%m-%d %H:%M:%S', \n",
    "errors = 'coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 28267 entries, 0 to 28266\n",
      "Data columns (total 10 columns):\n",
      " #   Column                Non-Null Count  Dtype         \n",
      "---  ------                --------------  -----         \n",
      " 0   i_id                  28267 non-null  float64       \n",
      " 1   departure_terminal    28267 non-null  object        \n",
      " 2   checkin_terminal      28267 non-null  object        \n",
      " 3   airline_grouped_hash  28267 non-null  object        \n",
      " 4   cco_hash              28267 non-null  object        \n",
      " 5   flt_hash              28267 non-null  object        \n",
      " 6   t_st                  28267 non-null  datetime64[ns]\n",
      " 7   m_city_rus1           28267 non-null  object        \n",
      " 8   m_city_rus2           28267 non-null  object        \n",
      " 9   config                28267 non-null  int64         \n",
      "dtypes: datetime64[ns](1), float64(1), int64(1), object(7)\n",
      "memory usage: 2.2+ MB\n"
     ]
    }
   ],
   "source": [
    "flight_rasp_v2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "flight_rasp_v2['t_st_year'] = flight_rasp_v2['t_st'].dt.year\n",
    "flight_rasp_v2['t_st_month'] = flight_rasp_v2['t_st'].dt.month\n",
    "flight_rasp_v2['t_st_day'] = flight_rasp_v2['t_st'].dt.day\n",
    "flight_rasp_v2['t_st_hour'] = flight_rasp_v2['t_st'].dt.hour\n",
    "flight_rasp_v2['t_st_minute'] = flight_rasp_v2['t_st'].dt.minute\n",
    "flight_rasp_v2['t_st_second'] = flight_rasp_v2['t_st'].dt.second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flight_rasp_v2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "flight_rasp_v2 = flight_rasp_v2.drop(['t_st'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(flight_rasp_v2['departure_terminal'])\n",
    "flight_rasp_v2['departure_terminal'] = le.transform(flight_rasp_v2['departure_terminal'])\n",
    "\n",
    "le.fit(flight_rasp_v2['checkin_terminal'])\n",
    "flight_rasp_v2['checkin_terminal'] = le.transform(flight_rasp_v2['checkin_terminal'])\n",
    "\n",
    "le.fit(flight_rasp_v2['airline_grouped_hash'])\n",
    "flight_rasp_v2['airline_grouped_hash'] = le.transform(flight_rasp_v2['airline_grouped_hash'])\n",
    "\n",
    "\n",
    "le.fit(flight_rasp_v2['cco_hash'])\n",
    "flight_rasp_v2['cco_hash'] = le.transform(flight_rasp_v2['cco_hash'])\n",
    "\n",
    "\n",
    "le.fit(flight_rasp_v2['flt_hash'])\n",
    "flight_rasp_v2['flt_hash'] = le.transform(flight_rasp_v2['flt_hash'])\n",
    "\n",
    "le.fit(flight_rasp_v2['m_city_rus1'])\n",
    "flight_rasp_v2['m_city_rus1'] = le.transform(flight_rasp_v2['m_city_rus1'])\n",
    "\n",
    "le.fit(flight_rasp_v2['m_city_rus2'])\n",
    "flight_rasp_v2['m_city_rus2'] = le.transform(flight_rasp_v2['m_city_rus2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>departure_terminal</th>\n",
       "      <th>checkin_terminal</th>\n",
       "      <th>airline_grouped_hash</th>\n",
       "      <th>cco_hash</th>\n",
       "      <th>flt_hash</th>\n",
       "      <th>m_city_rus1</th>\n",
       "      <th>m_city_rus2</th>\n",
       "      <th>config</th>\n",
       "      <th>t_st_year</th>\n",
       "      <th>t_st_month</th>\n",
       "      <th>t_st_day</th>\n",
       "      <th>t_st_hour</th>\n",
       "      <th>t_st_minute</th>\n",
       "      <th>t_st_second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>34</td>\n",
       "      <td>265</td>\n",
       "      <td>0</td>\n",
       "      <td>109</td>\n",
       "      <td>156</td>\n",
       "      <td>2023</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>227</td>\n",
       "      <td>0</td>\n",
       "      <td>114</td>\n",
       "      <td>202</td>\n",
       "      <td>2023</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>34</td>\n",
       "      <td>169</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>158</td>\n",
       "      <td>2023</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>34</td>\n",
       "      <td>385</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>156</td>\n",
       "      <td>2023</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>34</td>\n",
       "      <td>326</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>196</td>\n",
       "      <td>2023</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   departure_terminal  checkin_terminal  airline_grouped_hash  cco_hash  \\\n",
       "0                   0                 0                    21        34   \n",
       "1                   1                 1                    11        11   \n",
       "2                   0                 0                    21        34   \n",
       "3                   0                 0                    21        34   \n",
       "4                   0                 0                    21        34   \n",
       "\n",
       "   flt_hash  m_city_rus1  m_city_rus2  config  t_st_year  t_st_month  \\\n",
       "0       265            0          109     156       2023           7   \n",
       "1       227            0          114     202       2023           7   \n",
       "2       169            0           25     158       2023           7   \n",
       "3       385            0           41     156       2023           7   \n",
       "4       326            0            1     196       2023           7   \n",
       "\n",
       "   t_st_day  t_st_hour  t_st_minute  t_st_second  \n",
       "0         8          0            5            0  \n",
       "1         8          0            5            0  \n",
       "2         8          0           10            0  \n",
       "3         8          0           10            0  \n",
       "4         8          0           15            0  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flight_rasp_v2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = flight_rasp_v2.drop('sum_bsm', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "flight_rasp_v2.to_csv(\"final_table_with_x_y.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = flight_rasp_v2['sum_bsm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test =  train_test_split(X,y,test_size = 0.1, random_state= 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "25440/25440 [==============================] - 81s 3ms/step - loss: 7299.3315 - accuracy: 0.0010\n",
      "Epoch 2/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 6366.3105 - accuracy: 8.2547e-04\n",
      "Epoch 3/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 5866.7837 - accuracy: 8.2547e-04\n",
      "Epoch 4/200\n",
      "25440/25440 [==============================] - 80s 3ms/step - loss: 4402.3628 - accuracy: 0.0017\n",
      "Epoch 5/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 2979.5894 - accuracy: 0.0300\n",
      "Epoch 6/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 2129.4075 - accuracy: 0.0373\n",
      "Epoch 7/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 1814.5651 - accuracy: 0.0399\n",
      "Epoch 8/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 1588.6257 - accuracy: 0.0467\n",
      "Epoch 9/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 1785.3636 - accuracy: 0.0458\n",
      "Epoch 10/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 1571.1851 - accuracy: 0.0381\n",
      "Epoch 11/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 2301.8801 - accuracy: 0.0073\n",
      "Epoch 12/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 2420.6875 - accuracy: 0.0032\n",
      "Epoch 13/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 1580.2412 - accuracy: 0.0094\n",
      "Epoch 14/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 1395.5371 - accuracy: 0.0234\n",
      "Epoch 15/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 1330.7543 - accuracy: 0.0402\n",
      "Epoch 16/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 1278.6769 - accuracy: 0.0463\n",
      "Epoch 17/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 1191.4514 - accuracy: 0.0517\n",
      "Epoch 18/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 1256.4065 - accuracy: 0.0484\n",
      "Epoch 19/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 1116.4705 - accuracy: 0.0403\n",
      "Epoch 20/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 1214.2892 - accuracy: 0.0430\n",
      "Epoch 21/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 1094.4706 - accuracy: 0.0626\n",
      "Epoch 22/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 1074.5765 - accuracy: 0.0899\n",
      "Epoch 23/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 1066.2466 - accuracy: 0.0746\n",
      "Epoch 24/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 1023.3251 - accuracy: 0.0860\n",
      "Epoch 25/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 968.9645 - accuracy: 0.0800\n",
      "Epoch 26/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 980.6009 - accuracy: 0.0742\n",
      "Epoch 27/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 957.3897 - accuracy: 0.0903\n",
      "Epoch 28/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 989.1537 - accuracy: 0.0728\n",
      "Epoch 29/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 988.1901 - accuracy: 0.0691\n",
      "Epoch 30/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 961.7399 - accuracy: 0.0615\n",
      "Epoch 31/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 922.6703 - accuracy: 0.0842\n",
      "Epoch 32/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 888.1223 - accuracy: 0.0783\n",
      "Epoch 33/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 928.5718 - accuracy: 0.0739\n",
      "Epoch 34/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 885.5641 - accuracy: 0.0702\n",
      "Epoch 35/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 871.3610 - accuracy: 0.0849\n",
      "Epoch 36/200\n",
      "25440/25440 [==============================] - 81s 3ms/step - loss: 843.2023 - accuracy: 0.0830\n",
      "Epoch 37/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 858.1230 - accuracy: 0.0893\n",
      "Epoch 38/200\n",
      "25440/25440 [==============================] - 82s 3ms/step - loss: 863.4796 - accuracy: 0.0833\n",
      "Epoch 39/200\n",
      "25440/25440 [==============================] - 80s 3ms/step - loss: 881.1100 - accuracy: 0.0941\n",
      "Epoch 40/200\n",
      "25440/25440 [==============================] - 80s 3ms/step - loss: 837.9628 - accuracy: 0.0890\n",
      "Epoch 41/200\n",
      "25440/25440 [==============================] - 82s 3ms/step - loss: 816.4670 - accuracy: 0.0936\n",
      "Epoch 42/200\n",
      "25440/25440 [==============================] - 81s 3ms/step - loss: 823.9481 - accuracy: 0.0891\n",
      "Epoch 43/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 856.7576 - accuracy: 0.0931\n",
      "Epoch 44/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 802.1364 - accuracy: 0.0904\n",
      "Epoch 45/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 792.6593 - accuracy: 0.1043\n",
      "Epoch 46/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 800.0062 - accuracy: 0.0927\n",
      "Epoch 47/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 799.2049 - accuracy: 0.0913\n",
      "Epoch 48/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 781.1762 - accuracy: 0.1080\n",
      "Epoch 49/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 833.2914 - accuracy: 0.0879\n",
      "Epoch 50/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 766.4538 - accuracy: 0.0897\n",
      "Epoch 51/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 818.3594 - accuracy: 0.0873\n",
      "Epoch 52/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 753.7775 - accuracy: 0.0906\n",
      "Epoch 53/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 767.7172 - accuracy: 0.0991\n",
      "Epoch 54/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 762.1992 - accuracy: 0.0945\n",
      "Epoch 55/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 773.6005 - accuracy: 0.0866\n",
      "Epoch 56/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 745.6154 - accuracy: 0.1003\n",
      "Epoch 57/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 734.7095 - accuracy: 0.0931\n",
      "Epoch 58/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 755.5883 - accuracy: 0.1001\n",
      "Epoch 59/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 771.9006 - accuracy: 0.1000\n",
      "Epoch 60/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 753.9242 - accuracy: 0.0995\n",
      "Epoch 61/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 737.9063 - accuracy: 0.1010\n",
      "Epoch 62/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 735.8909 - accuracy: 0.1011\n",
      "Epoch 63/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 719.7801 - accuracy: 0.1066\n",
      "Epoch 64/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 710.3139 - accuracy: 0.0886\n",
      "Epoch 65/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 747.9877 - accuracy: 0.0882\n",
      "Epoch 66/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 717.4454 - accuracy: 0.1104\n",
      "Epoch 67/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 716.8923 - accuracy: 0.1086\n",
      "Epoch 68/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 718.0740 - accuracy: 0.1006\n",
      "Epoch 69/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 699.2307 - accuracy: 0.0991\n",
      "Epoch 70/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 702.4732 - accuracy: 0.0976\n",
      "Epoch 71/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 695.3763 - accuracy: 0.0819\n",
      "Epoch 72/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 682.4359 - accuracy: 0.0720\n",
      "Epoch 73/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 687.3498 - accuracy: 0.0812\n",
      "Epoch 74/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 688.2953 - accuracy: 0.0783\n",
      "Epoch 75/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 674.2369 - accuracy: 0.0726\n",
      "Epoch 76/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 726.4047 - accuracy: 0.0732\n",
      "Epoch 77/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 851.9599 - accuracy: 0.0524\n",
      "Epoch 78/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 692.3318 - accuracy: 0.0600\n",
      "Epoch 79/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 696.0219 - accuracy: 0.0642\n",
      "Epoch 80/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 729.6103 - accuracy: 0.0831\n",
      "Epoch 81/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 729.9790 - accuracy: 0.0820\n",
      "Epoch 82/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 715.0994 - accuracy: 0.0855\n",
      "Epoch 83/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 687.8633 - accuracy: 0.0911\n",
      "Epoch 84/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 670.2429 - accuracy: 0.0936\n",
      "Epoch 85/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 664.5430 - accuracy: 0.0903\n",
      "Epoch 86/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 678.6720 - accuracy: 0.0811\n",
      "Epoch 87/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 664.5031 - accuracy: 0.0836\n",
      "Epoch 88/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 646.4523 - accuracy: 0.0841\n",
      "Epoch 89/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 650.0828 - accuracy: 0.0842\n",
      "Epoch 90/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 631.0941 - accuracy: 0.0932\n",
      "Epoch 91/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 669.7874 - accuracy: 0.0951\n",
      "Epoch 92/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 689.6900 - accuracy: 0.0646\n",
      "Epoch 93/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 649.2728 - accuracy: 0.0793\n",
      "Epoch 94/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 649.0337 - accuracy: 0.0739\n",
      "Epoch 95/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 649.2311 - accuracy: 0.0777\n",
      "Epoch 96/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 655.3625 - accuracy: 0.0765\n",
      "Epoch 97/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 634.3276 - accuracy: 0.0683\n",
      "Epoch 98/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 635.5403 - accuracy: 0.0776\n",
      "Epoch 99/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 715.1676 - accuracy: 0.0840\n",
      "Epoch 100/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 720.2393 - accuracy: 0.0780\n",
      "Epoch 101/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 625.1633 - accuracy: 0.0951\n",
      "Epoch 102/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 632.7809 - accuracy: 0.0967\n",
      "Epoch 103/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 737.1765 - accuracy: 0.0627\n",
      "Epoch 104/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 775.4115 - accuracy: 0.0360\n",
      "Epoch 105/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 692.1591 - accuracy: 0.0643\n",
      "Epoch 106/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 668.9067 - accuracy: 0.0901\n",
      "Epoch 107/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 711.7200 - accuracy: 0.0831\n",
      "Epoch 108/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 622.4966 - accuracy: 0.0938\n",
      "Epoch 109/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 649.6332 - accuracy: 0.0724\n",
      "Epoch 110/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 665.9749 - accuracy: 0.0713\n",
      "Epoch 111/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 652.5621 - accuracy: 0.1055\n",
      "Epoch 112/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 626.7177 - accuracy: 0.1074\n",
      "Epoch 113/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 637.2579 - accuracy: 0.0960\n",
      "Epoch 114/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 630.8950 - accuracy: 0.1050\n",
      "Epoch 115/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 631.5698 - accuracy: 0.0931\n",
      "Epoch 116/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 622.3680 - accuracy: 0.0945\n",
      "Epoch 117/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 628.0489 - accuracy: 0.0977\n",
      "Epoch 118/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 629.6873 - accuracy: 0.1061\n",
      "Epoch 119/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 616.3362 - accuracy: 0.0917\n",
      "Epoch 120/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 637.0826 - accuracy: 0.0921\n",
      "Epoch 121/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 622.0844 - accuracy: 0.0896\n",
      "Epoch 122/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 677.4949 - accuracy: 0.0607\n",
      "Epoch 123/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 628.0001 - accuracy: 0.0785\n",
      "Epoch 124/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 622.0334 - accuracy: 0.0921\n",
      "Epoch 125/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 605.9919 - accuracy: 0.0962\n",
      "Epoch 126/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 655.2007 - accuracy: 0.1054\n",
      "Epoch 127/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 622.0173 - accuracy: 0.1003\n",
      "Epoch 128/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 612.3083 - accuracy: 0.0909\n",
      "Epoch 129/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 638.3846 - accuracy: 0.0941\n",
      "Epoch 130/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 606.9824 - accuracy: 0.1098\n",
      "Epoch 131/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 697.2025 - accuracy: 0.1040\n",
      "Epoch 132/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 639.8352 - accuracy: 0.0965\n",
      "Epoch 133/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 609.0336 - accuracy: 0.0991\n",
      "Epoch 134/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 649.5740 - accuracy: 0.0941\n",
      "Epoch 135/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 682.9102 - accuracy: 0.0899\n",
      "Epoch 136/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 635.8187 - accuracy: 0.0948\n",
      "Epoch 137/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 583.5616 - accuracy: 0.1055\n",
      "Epoch 138/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 615.6997 - accuracy: 0.1077\n",
      "Epoch 139/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 665.8414 - accuracy: 0.1028\n",
      "Epoch 140/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 626.1148 - accuracy: 0.0964\n",
      "Epoch 141/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 603.2374 - accuracy: 0.0965\n",
      "Epoch 142/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 591.4620 - accuracy: 0.1017\n",
      "Epoch 143/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 645.4407 - accuracy: 0.1020\n",
      "Epoch 144/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 622.5457 - accuracy: 0.1082\n",
      "Epoch 145/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 599.8239 - accuracy: 0.1122\n",
      "Epoch 146/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 618.9781 - accuracy: 0.1039\n",
      "Epoch 147/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 625.1838 - accuracy: 0.1057\n",
      "Epoch 148/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 629.9108 - accuracy: 0.1010\n",
      "Epoch 149/200\n",
      "25440/25440 [==============================] - 80s 3ms/step - loss: 633.3578 - accuracy: 0.1022\n",
      "Epoch 150/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 616.1545 - accuracy: 0.1100\n",
      "Epoch 151/200\n",
      "25440/25440 [==============================] - 80s 3ms/step - loss: 622.9935 - accuracy: 0.1079\n",
      "Epoch 152/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 732.2053 - accuracy: 0.0969\n",
      "Epoch 153/200\n",
      "25440/25440 [==============================] - 80s 3ms/step - loss: 602.5860 - accuracy: 0.1096\n",
      "Epoch 154/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 605.1959 - accuracy: 0.1049\n",
      "Epoch 155/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 619.5474 - accuracy: 0.1031\n",
      "Epoch 156/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 617.8448 - accuracy: 0.1050\n",
      "Epoch 157/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 856.2426 - accuracy: 0.0833\n",
      "Epoch 158/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 661.2139 - accuracy: 0.0933\n",
      "Epoch 159/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 609.5616 - accuracy: 0.0862\n",
      "Epoch 160/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 584.9213 - accuracy: 0.0902\n",
      "Epoch 161/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 602.3000 - accuracy: 0.0847\n",
      "Epoch 162/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 678.8541 - accuracy: 0.0861\n",
      "Epoch 163/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 653.8954 - accuracy: 0.0805\n",
      "Epoch 164/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 755.5228 - accuracy: 0.0765\n",
      "Epoch 165/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 671.3964 - accuracy: 0.0905\n",
      "Epoch 166/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 630.6631 - accuracy: 0.1020\n",
      "Epoch 167/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 592.8935 - accuracy: 0.1042\n",
      "Epoch 168/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 606.9235 - accuracy: 0.1088\n",
      "Epoch 169/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 603.9032 - accuracy: 0.1023\n",
      "Epoch 170/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 590.7713 - accuracy: 0.1149\n",
      "Epoch 171/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 576.1693 - accuracy: 0.1172\n",
      "Epoch 172/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 604.1222 - accuracy: 0.1108\n",
      "Epoch 173/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 655.7020 - accuracy: 0.1212\n",
      "Epoch 174/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 626.4958 - accuracy: 0.1098\n",
      "Epoch 175/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 620.7040 - accuracy: 0.1093\n",
      "Epoch 176/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 623.1471 - accuracy: 0.1070\n",
      "Epoch 177/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 601.4493 - accuracy: 0.0965\n",
      "Epoch 178/200\n",
      "25440/25440 [==============================] - 80s 3ms/step - loss: 614.8968 - accuracy: 0.1070\n",
      "Epoch 179/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 595.5905 - accuracy: 0.1051\n",
      "Epoch 180/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 657.9029 - accuracy: 0.1045\n",
      "Epoch 181/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 573.0251 - accuracy: 0.1093\n",
      "Epoch 182/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 592.8663 - accuracy: 0.1076\n",
      "Epoch 183/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 581.3306 - accuracy: 0.1030\n",
      "Epoch 184/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 564.9312 - accuracy: 0.1170\n",
      "Epoch 185/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 634.4254 - accuracy: 0.1159\n",
      "Epoch 186/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 587.0579 - accuracy: 0.1216\n",
      "Epoch 187/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 576.2258 - accuracy: 0.1182\n",
      "Epoch 188/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 588.6001 - accuracy: 0.1199\n",
      "Epoch 189/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 573.1421 - accuracy: 0.1201\n",
      "Epoch 190/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 576.7122 - accuracy: 0.1271\n",
      "Epoch 191/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 583.4889 - accuracy: 0.1264\n",
      "Epoch 192/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 577.0911 - accuracy: 0.1260\n",
      "Epoch 193/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 627.0449 - accuracy: 0.1235\n",
      "Epoch 194/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 574.6981 - accuracy: 0.1223\n",
      "Epoch 195/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 611.8286 - accuracy: 0.1183\n",
      "Epoch 196/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 572.8778 - accuracy: 0.1163\n",
      "Epoch 197/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 595.4689 - accuracy: 0.1154\n",
      "Epoch 198/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 620.1027 - accuracy: 0.1155\n",
      "Epoch 199/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 590.1337 - accuracy: 0.1002\n",
      "Epoch 200/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 621.9506 - accuracy: 0.1095\n"
     ]
    }
   ],
   "source": [
    "#RNN\n",
    "from keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from keras.layers import Activation, Dense\n",
    "\n",
    "model2 = Sequential()\n",
    "model2.add(LSTM(X_train.shape[1], return_sequences=True, input_shape=[X_train.shape[1], 1]))\n",
    "model2.add(LSTM(X_train.shape[1], return_sequences=False))\n",
    "model2.add(Dense(1))\n",
    "model2.compile(optimizer='adam', loss = 'mean_squared_error', metrics=['accuracy'])\n",
    "history = model2.fit(X_train, y_train, batch_size = 1, epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# save the model to disk\n",
    "filename = 'RNN_model_200.sav'\n",
    "pickle.dump(model2, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model from disk\n",
    "filename = 'RNN_model_200.sav'\n",
    "loaded_model = pickle.load(open(filename, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for training\n",
    "import pandas as  pd\n",
    "\n",
    "xy = pd.read_csv(\"final_table_with_x_y.csv\")\n",
    "\n",
    "X = xy.drop('sum_bsm', axis=1)\n",
    "y = xy['sum_bsm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for training\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test =  train_test_split(X,y,test_size = 0.1, random_state= 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89/89 [==============================] - 1s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "pred1 = loaded_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame(pred1)\n",
    "df1.to_csv('pred1.csv', index = False)\n",
    "y_test.to_csv('y_test.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_ = y_test\n",
    "pred1.sort(axis=0)\n",
    "new_numpy = y_test_.to_numpy(dtype=int)\n",
    "new_numpy.sort(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAigAAAGdCAYAAAA44ojeAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAABHiElEQVR4nO3deXhU5f3//+dMlsk6E7ITSSDshFUChqjVCpGAcQWtWlSsVCsNuKBI6Udxab9isVWrRax+LNC6VX8fN6gboKCWsAVRBImASMBkEiAkk3Umy/n9MWTCCAKBwEyS1+O65pqz3GfyPh6SeXmf+5xjMgzDQERERMSPmH1dgIiIiMiPKaCIiIiI31FAEREREb+jgCIiIiJ+RwFFRERE/I4CioiIiPgdBRQRERHxOwooIiIi4ncCfV3AyWhqaqKoqIjIyEhMJpOvyxEREZETYBgGlZWVJCUlYTYfu4+kXQaUoqIikpOTfV2GiIiInIQ9e/bQrVu3Y7ZplwElMjIScO+g1Wr1cTUiIiJyIhwOB8nJyZ7v8WNplwGl+bSO1WpVQBEREWlnTmR4hgbJioiIiN9RQBERERG/o4AiIiIifkcBRURERPyOAoqIiIj4HQUUERER8TsKKCIiIuJ3FFBERETE7yigiIiIiN9RQBERERG/o4AiIiIifkcBRURERPyOAoqIiIi0+OADuPNOeP11n5ahgCIiIiIt1q2Dp5+GTz7xaRkKKCIiItLCMHxdAaCAIiIiIkdjMvn0xyugiIiISAv1oIiIiIjfaQ4o7akHpUePHphMpiNeubm5ANTV1ZGbm0tMTAwRERFMnDiRkpISr88oLCwkJyeHsLAw4uPjmTlzJg0NDW23RyIiInLq2lNAWb9+PcXFxZ7XsmXLALjmmmsAuPvuu1myZAlvvPEGq1atoqioiAkTJni2b2xsJCcnB5fLxerVq1m8eDGLFi1izpw5bbhLIiIictLa4ymeuLg4EhMTPa+lS5fSq1cvLrzwQioqKnjxxRd54oknGD16NOnp6SxcuJDVq1ezZs0aAD766CO2bt3KSy+9xLBhwxg/fjx/+MMfmD9/Pi6X67TsoIiIiJyE9tSDcjiXy8VLL73ELbfcgslkIj8/n/r6erKysjxt+vfvT0pKCnl5eQDk5eUxePBgEhISPG2ys7NxOBxs2bLlFHZDRERE2oSf9KAEnuyGb7/9NuXl5dx8880A2O12goODiYqK8mqXkJCA3W73tDk8nDSvb173U5xOJ06n0zPvcDhOtmwRERE5Ee21B+XFF19k/PjxJCUltWU9RzV37lxsNpvnlZycfNp/poiISKfkJz0oJxVQdu/ezfLly/n1r3/tWZaYmIjL5aK8vNyrbUlJCYmJiZ42P76qp3m+uc3RzJ49m4qKCs9rz549J1O2iIiInKj22IOycOFC4uPjycnJ8SxLT08nKCiIFStWeJYVFBRQWFhIZmYmAJmZmWzevJnS0lJPm2XLlmG1WklLS/vJn2exWLBarV4vEREROQ38pAel1WNQmpqaWLhwIZMnTyYwsGVzm83GlClTmDFjBtHR0VitVqZPn05mZiajRo0CYOzYsaSlpXHjjTcyb9487HY7999/P7m5uVgslrbbKxERETk1Pu5BaXVAWb58OYWFhdxyyy1HrHvyyScxm81MnDgRp9NJdnY2zz77rGd9QEAAS5cuZerUqWRmZhIeHs7kyZN55JFHTm0vREREpG201x6UsWPHYvxE8SEhIcyfP5/58+f/5Pbdu3fnvffea+2PFRERkTOpPY5BERERkQ7KT3pQFFBERESkRXt8WKCIiIh0EgooIiIi4jd0ikdERET8lnpQRERExG+oB0VERET8lnpQRERExG+oB0VERET8lnpQRERExG+oB0VERET8lnpQRERExG+oB0VERET8jm51LyIiIn5LAUVERET8hk7xiIiIiN9SD4qIiIj4DfWgiIiIiN9SD4qIiIj4DfWgiIiIiN9SD4qIiIj4DfWgiIiIiN9SD4qIiIj4DfWgiIiIiN/Rre5FRETEbymgiIiIiN/QKR4RERHxW+pBEREREb+hHhQRERHxW+pBEREREb+hHhQRERHxW+pBEREREb+hHhQRERHxW+pBEREREb+hHhQRERHxO+31Vvc//PADN9xwAzExMYSGhjJ48GA2bNjgWW8YBnPmzKFr166EhoaSlZXF9u3bvT6jrKyMSZMmYbVaiYqKYsqUKVRVVZ363oiIiEiH0KqAcvDgQc477zyCgoJ4//332bp1K3/5y1/o0qWLp828efN4+umnee6551i7di3h4eFkZ2dTV1fnaTNp0iS2bNnCsmXLWLp0KZ9++im33XZb2+2ViIiInBw/6UEJbE3jP/3pTyQnJ7Nw4ULPstTUVM+0YRg89dRT3H///VxxxRUA/POf/yQhIYG3336b6667jm+++YYPPviA9evXM2LECACeeeYZLrnkEv785z+TlJTUFvslIiIip6I9neJ59913GTFiBNdccw3x8fGcffbZvPDCC571u3btwm63k5WV5Vlms9nIyMggLy8PgLy8PKKiojzhBCArKwuz2czatWuP+nOdTicOh8PrJSIiIqdBexwk+91337FgwQL69OnDhx9+yNSpU7njjjtYvHgxAHa7HYCEhASv7RISEjzr7HY78fHxXusDAwOJjo72tPmxuXPnYrPZPK/k5OTWlC0iIiKt1Z56UJqamhg+fDiPPvooZ599Nrfddhu33norzz333OmqD4DZs2dTUVHhee3Zs+e0/jwREZFOqz32oHTt2pW0tDSvZQMGDKCwsBCAxMREAEpKSrzalJSUeNYlJiZSWlrqtb6hoYGysjJPmx+zWCxYrVavl4iIiJxG7akH5bzzzqOgoMBr2bfffkv37t0B94DZxMREVqxY4VnvcDhYu3YtmZmZAGRmZlJeXk5+fr6nzccff0xTUxMZGRknvSMiIiLSBvykB6VVV/HcfffdnHvuuTz66KP84he/YN26dTz//PM8//zzAJhMJu666y7++Mc/0qdPH1JTU3nggQdISkriyiuvBNw9LuPGjfOcGqqvr2fatGlcd911uoJHRETEX7Sny4xHjhzJW2+9xezZs3nkkUdITU3lqaeeYtKkSZ429913H9XV1dx2222Ul5dz/vnn88EHHxASEuJp8/LLLzNt2jTGjBmD2Wxm4sSJPP300223VyIiInJy/KQHxWQYflJJKzgcDmw2GxUVFRqPIiIi0pZ+9StYtAj+9Ce47742/ejWfH/rWTwiIiLSwk/6LRRQREREpIWf3OpeAUVERESOpIAiIiIifkOneERERMRvqQdFRERE/IZ6UERERMRvqQdFRERE/IZ6UERERMRvqQdFRERE/IZ6UERERMRvqQdFRERE/IZ6UERERMTv6Fb3IiIi4neamtzvZt9GBAUUERERadHY6H4PCPBpGQooIiIi0kIBRURERPyOAoqIiIj4HQUUERER8TsKKCIiIuJ3FFBERETE7yigiIiIiN9RQBERERG/o4AiIiIifkcBRURERPyOAoqIiIj4HQUUERER8TsNDe53BRQRERHxG5WV7vfISJ+WoYAiIiIiLSoq3O82m0/LUEARERERN8NQQBERERE/U1PTMkhWAUVERET8QnPvSUAAhIf7tBQFFBEREXFrDihWK5hMPi1FAUVERETc9u93v/v49A60MqA89NBDmEwmr1f//v096+vq6sjNzSUmJoaIiAgmTpxISUmJ12cUFhaSk5NDWFgY8fHxzJw5k4bma65FRETEd55/3v0eGurbOoDA1m4wcOBAli9f3vIBgS0fcffdd/Of//yHN954A5vNxrRp05gwYQL//e9/AWhsbCQnJ4fExERWr15NcXExN910E0FBQTz66KNtsDsiIiJy0oKC3O9+0IPS6oASGBhIYmLiEcsrKip48cUXeeWVVxg9ejQACxcuZMCAAaxZs4ZRo0bx0UcfsXXrVpYvX05CQgLDhg3jD3/4A7NmzeKhhx4iODj41PdIRERETk7zFTwTJvi2Dk5iDMr27dtJSkqiZ8+eTJo0icLCQgDy8/Opr68nKyvL07Z///6kpKSQl5cHQF5eHoMHDyYhIcHTJjs7G4fDwZYtW37yZzqdThwOh9dLRERE2pifPIcHWhlQMjIyWLRoER988AELFixg165d/OxnP6OyshK73U5wcDBRUVFe2yQkJGC32wGw2+1e4aR5ffO6nzJ37lxsNpvnlZyc3JqyRURE5ET4UUBp1Sme8ePHe6aHDBlCRkYG3bt35/XXXyf0NA6omT17NjNmzPDMOxwOhRQREZG25kcB5ZQuM46KiqJv377s2LGDxMREXC4X5eXlXm1KSko8Y1YSExOPuKqnef5o41qaWSwWrFar10tERETaWEcJKFVVVezcuZOuXbuSnp5OUFAQK1as8KwvKCigsLCQzMxMADIzM9m8eTOlpaWeNsuWLcNqtZKWlnYqpYiIiMip8qOA0qpTPPfeey+XXXYZ3bt3p6ioiAcffJCAgACuv/56bDYbU6ZMYcaMGURHR2O1Wpk+fTqZmZmMGjUKgLFjx5KWlsaNN97IvHnzsNvt3H///eTm5mKxWE7LDoqIiMgJaq8BZe/evVx//fUcOHCAuLg4zj//fNasWUNcXBwATz75JGazmYkTJ+J0OsnOzubZZ5/1bB8QEMDSpUuZOnUqmZmZhIeHM3nyZB555JG23SsRERFpPT8KKCbDMAxfF9FaDocDm81GRUWFxqOIiIi0lexs+Ogj+Oc/4cYb2/zjW/P9rWfxiIiIiJsf9aAooIiIiIibAoqIiIj4HQUUERER8TsNDe73wFY/qq/NKaCIiIiIW329+90PHt6rgCIiIiJuTqf7XQFFRERE/IbL5X5XQBERERG/oYAiIiIifkcBRURERPyOAoqIiIj4HQUUERER8TsKKCIiIuJ3FFBERETErzQ2ttzqXgFFRERE/ELzXWRBAUVERET8RPPpHVBAERERET9xeEAJCvJdHYcooIiIiAjU1Ljfg4MhIMC3taCAIiIiIgCVle73yEjf1nGIAoqIiIgooIiIiIgfOnAAgHqrjcfe34a9os6n5SigiIiICOzdC0BhWDTPrdrJ3f/e5NNyFFBERETE04NiD3af4slKS/BlNQooIiIiApSVAeAIcweUSEugL6tRQBERERE8AaUixB1QLEG+jQgKKCIiIuIJKAdDIgAICfLtvVAUUERERATeeQeA/WFRgAKKiIiI+FphoWdyZ3Q3AEICdYpHREREfGnPHs/kt80BRT0oIiIi4lO1te73QYOoa2gCFFBERETE1w4FlKaQUMqq3U81DtFVPCIiIuJThwLKD04DgKAAE7ERFl9WpIAiIiLS6ZWWAnDQHALAhX3jCNeN2kRERMSnHnsMgC8T+wBwdXqyL6sBFFBEREQ6t23b4IcfAHit6zDMJjgnNdrHRZ1iQHnssccwmUzcddddnmV1dXXk5uYSExNDREQEEydOpKSkxGu7wsJCcnJyCAsLIz4+npkzZ9LQ0HAqpYiIiMjJ2LABgOrkHmxJ6MWgs2xEhwf7uKhTCCjr16/n73//O0OGDPFafvfdd7NkyRLeeOMNVq1aRVFRERMmTPCsb2xsJCcnB5fLxerVq1m8eDGLFi1izpw5J78XIiIicnIOdSLs6T0IgH4Jkb6sxuOkAkpVVRWTJk3ihRdeoEuXLp7lFRUVvPjiizzxxBOMHj2a9PR0Fi5cyOrVq1mzZg0AH330EVu3buWll15i2LBhjB8/nj/84Q/Mnz8fl8vVNnslIiIiJ2bnTgC+D4sBoE9ChC+r8TipgJKbm0tOTg5ZWVley/Pz86mvr/da3r9/f1JSUsjLywMgLy+PwYMHk5CQ4GmTnZ2Nw+Fgy5YtR/15TqcTh8Ph9RIREZE2cOi790OaA4p/9KC0+hqi1157jY0bN7J+/foj1tntdoKDg4mKivJanpCQgN1u97Q5PJw0r29edzRz587l4Ycfbm2pIiIicjxbtwLwbWwKcZEW0rt3Oc4GZ0arelD27NnDnXfeycsvv0xISMjpqukIs2fPpqKiwvPac9gzA0REROQklZbC/v00YWJnTDcW3jwSa0iQr6sCWhlQ8vPzKS0tZfjw4QQGBhIYGMiqVat4+umnCQwMJCEhAZfLRXl5udd2JSUlJCYmApCYmHjEVT3N881tfsxisWC1Wr1eIiIicooOnd7ZE5VAXVAI/RP94/QOtDKgjBkzhs2bN7Np0ybPa8SIEUyaNMkzHRQUxIoVKzzbFBQUUFhYSGZmJgCZmZls3ryZ0kN3rQNYtmwZVquVtLS0NtotEREROa5Dp3e2xyQTFRZEYID/3B6tVWNQIiMjGTRokNey8PBwYmJiPMunTJnCjBkziI6Oxmq1Mn36dDIzMxk1ahQAY8eOJS0tjRtvvJF58+Zht9u5//77yc3NxWLx7X3/RUREOpVDPSjbY7tz7Ujf3z32cG1+o/0nn3wSs9nMxIkTcTqdZGdn8+yzz3rWBwQEsHTpUqZOnUpmZibh4eFMnjyZRx55pK1LERERkWM5bIDsr4cm+bgYbybDMAxfF9FaDocDm81GRUWFxqOIiIicjIYGjNhYTBUVXDr5KZ5/6jaSokJP649szfe3/5xsEhERkTPnhx8wVVTgDAjkQO/+JFrP3NW5J0IBRUREpBPav+JT93tYF24f3Q+z2eTjirwpoIiIiHRCm15+F4DK0Ai/GyALCigiIiKdj2Fw/qfugBJy802EBAX4uKAjKaCIiIh0MqVLPiSkwf2A3ribf+njao5OAUVERKSTiZl4OQAlkbGED+jr42qOTgFFRESkM1m/noCGegBW3jDNx8X8NAUUERGRTsSYN88zHXfH7T6s5NgUUERERDoRY8MGAF4eNo4RPaJ9XM1PU0ARERHpLAwD8/ffA7AqNZ3w4DZ/4k2bUUARERHpLCoqPJP5vc8mwM9uznY4BRQREZHOYt06AA6EWjH5+bPsFFBEREQ6i82bAQgwmgjz49M7oIAiIiLSeZSXA/B5j7MJC/a/u8ceTgFFRESksygrA2BndDfCLepBEREREX9wKKCUh0aoB0VERET8xJIlAFSERPj1JcaggCIiItI57N4N1dUAfJnYlzCLelBERETE1/LzAagLDWdnbDKJ1hAfF3RsCigiIiKdwcaNAKwZMQaA7jFhvqzmuBRQREREOoNDAeWLmFQAuseE+7Ka41JAERER6egaGmD1agA+tXUH1IMiIiIivrZtG1RU0BQRyaaE3oQGBWgMioiIiPjYodM7Ff0HYpjM9IgNx2Ty3wcFggKKiIhIx3cooOzt0R+AnrH+Pf4EFFBEREQ6NsOABQsAWBqQCECv+AhfVnRCFFBEREQ6sg8/BJcLgP906YPJBDdkpPi4qONTQBEREenIVqzwTO61JZDW1Uq8nw+QBQUUERGRjquuDv78ZwA+vX02AH3awekdUEARERHpuF59tWWyz/kADOkW5aNiWkcBRUREpKP6y1/c7z178pXLfVpnaLLNhwWdOAUUERGRjqqyEoD6GfdQVFELQEq0/19iDAooIiIiHZPdDoWFYDLx/bgrMQwIDw4gNiLY15WdEAUUERGRjmjkSPf70KGs398AwKCzbH5/B9lmrQooCxYsYMiQIVitVqxWK5mZmbz//vue9XV1deTm5hITE0NERAQTJ06kpKTE6zMKCwvJyckhLCyM+Ph4Zs6cSUNDQ9vsjYiIiMDXX8Peve7pm24i77sDAGT0jPFhUa3TqoDSrVs3HnvsMfLz89mwYQOjR4/miiuuYMuWLQDcfffdLFmyhDfeeINVq1ZRVFTEhAkTPNs3NjaSk5ODy+Vi9erVLF68mEWLFjFnzpy23SsREZHO7KGHPJP1d9zJyoJSAC7sG+ujglrPZBiGcSofEB0dzeOPP87VV19NXFwcr7zyCldffTUA27ZtY8CAAeTl5TFq1Cjef/99Lr30UoqKikhISADgueeeY9asWezbt4/g4BM7L+ZwOLDZbFRUVGC1Wk+lfBERkY5n8GB3L8qjj/L51bdyw4triY0IZu3vswgw++4UT2u+v096DEpjYyOvvfYa1dXVZGZmkp+fT319PVlZWZ42/fv3JyUlhby8PADy8vIYPHiwJ5wAZGdn43A4PL0wR+N0OnE4HF4vEREROQrDcIcTgJwcvtxbDsB5vWN9Gk5aq9UBZfPmzURERGCxWLj99tt56623SEtLw263ExwcTFRUlFf7hIQE7HY7AHa73SucNK9vXvdT5s6di81m87ySk5NbW7aIiEjn8Pjj7veAAEhJobzG/RyehHZwe/vDtTqg9OvXj02bNrF27VqmTp3K5MmT2bp16+mozWP27NlUVFR4Xnv27DmtP09ERKTdeu899/uAARg2m2eAbHR4+7i8uFlgazcIDg6md+/eAKSnp7N+/Xr++te/cu211+JyuSgvL/fqRSkpKSEx0f1458TERNatW+f1ec1X+TS3ORqLxYLFYmltqSIiIp1PqXtALE8/zVtf/MDXPzgICjBx2dAk39bVSqd8H5SmpiacTifp6ekEBQWx4rCnJhYUFFBYWEhmZiYAmZmZbN68mdLm/3jAsmXLsFqtpKWlnWopIiIisn+/+z06mtfWu884nNsrlrOiQn1YVOu1qgdl9uzZjB8/npSUFCorK3nllVdYuXIlH374ITabjSlTpjBjxgyio6OxWq1Mnz6dzMxMRo0aBcDYsWNJS0vjxhtvZN68edjtdu6//35yc3PVQyIiInKqDh6EffsAaEhO4Zs33Wctbr+wly+rOimtCiilpaXcdNNNFBcXY7PZGDJkCB9++CEXX3wxAE8++SRms5mJEyfidDrJzs7m2Wef9WwfEBDA0qVLmTp1KpmZmYSHhzN58mQeeeSRtt0rERGRzqj56p2UFPYHhFLpdN8IdUSPLj4s6uSc8n1QfEH3QRERETmKiRPhzTfh0kv5/ImFh+5/YmHD/VnH3/YMOCP3QRERERE/c+i+Y4wbx4bdZQAM7WbzYUEnTwFFRESkI6iqguJiABwTruGlNYUA/LxfnC+rOmkKKCIiIh3BZ5+532NiePXbSvZXOQkLDmh3lxc3U0ARERHpCP73f93vo0bxbUkVAL88J4WosPZ1g7ZmCigiIiLtXXW1e3As0HThhZ7n7wxup+NPQAFFRESk/fuf//FMfjn6CnaUuntQhqe0v8uLmymgiIiItGf5+fDXv7qnf/YzioIiARieEkVydJgPCzs1CigiIiLt2dKlLdMLFlDtct+czRoa5KOC2oYCioiISHv28svu97/8BQYOpNbVCEB4cKufB+xXFFBERETaq+++g+3b3dMZGQCUVbsA9aCIiIiIr9xxh/s9KgrOPReAAnslAInWEB8V1TYUUERERNqjpib4z3/c0088ASYTW4oq+GCLHYDz+8T4sLhTp4AiIiLSHjUPjrVY4IYbAFi/y/38ne4xYaR3j/ZVZW1CAUVERKS92bkTrrjCPW21QlAQm/aU89CSrQDkDO7qw+LahgKKiIhIe/Lii9C7d8v8nDlU1Nbz68UbADCZYMr5qT4qru0ooIiIiLQXjY0wa1bL/H33wbRpLPmyiP1VTswm+HTmRcREWHxXYxtp3xdJi4iIdBaGAQMHwoED7vm1a+Gcc1hZUMr9b38NwP/kpLXru8ceTj0oIiIi/s4w4KKLoKDAPX/OOTByJO9vLubmhesBCA0K4Orh3XxYZNtSQBEREfF3n3wCq1a1zK9Zg93hZOb/9xUAGanRfD7rImxh7fvmbIfTKR4RERF/1tAAY8a0zNfVUe1q5ILHP8HV0ESPmDAW33IOIUEBvqvxNFAPioiIiL+qr4cRI1rmP/oILBb+b+NeXA1NADx+zdAOF05AAUVERMR//b//B19+6Z6+5hq4+GLW7SpjzjtbALhiWBIje7TvG7L9FAUUERERf1RTAw8/7J7u2xf+9S/qG5uY/upGAMKDA5hxcV8fFnh6KaCIiIj4o7feapnOywOLhZfW7KbE4QTgg7suoHtMuI+KO/0UUERERPyN0+k+vQPuJxZHR1NW7eKp5dsB+J9LBnSY+538FAUUERERf2IYcN558M037vmpU6mrb+SG/11LRW09XcKCmDQqxbc1ngEKKCIiIv7k++8hP989PXky9O/Pf3fsZ2uxA4AFN6QTFtzx7xKigCIiIuJPPvrI/T50KCxaBMCBahcAw1OiGNUzxkeFnVkKKCIiIv7k3nvd70OGeBaVHQooHX3cyeEUUERERPzFK69AVZV7+qqrAGhsMpj3wTYAesdF+KqyM04BRURExF/cemvL9JVXAjD91Y00Ge5F5/buHKd3QAFFRETEP7z1lvvmbADLl4PJxO4D1by32Q7A5UOTSO/eMe8aezQKKCIiIr7mcsGECS3zhx4O+MaGvQDERliYd/WQo23ZYSmgiIiI+NqqVS3Th+5/kr/7IC989h0As8b165APBDyWVgWUuXPnMnLkSCIjI4mPj+fKK6+koKDAq01dXR25ubnExMQQERHBxIkTKSkp8WpTWFhITk4OYWFhxMfHM3PmTBoaGk59b0RERNqjlSvd75deCv37821JJdc8txpnQxM/6xPLxOHdfFqeL7QqoKxatYrc3FzWrFnDsmXLqK+vZ+zYsVRXV3va3H333SxZsoQ33niDVatWUVRUxITDuq0aGxvJycnB5XKxevVqFi9ezKJFi5gzZ07b7ZWIiEh7YRjw6KPu6YsvBuDTb/d5Bsb+7frhmM0mHxXnOybDMIyT3Xjfvn3Ex8ezatUqLrjgAioqKoiLi+OVV17h6quvBmDbtm0MGDCAvLw8Ro0axfvvv8+ll15KUVERCQkJADz33HPMmjWLffv2ERwcfNyf63A4sNlsVFRUYLVaT7Z8ERER33vlFZg0yT29ezekpHDxE6vYXlrFzOx+5F7U27f1taHWfH+f0hiUiooKAKKj3aOK8/Pzqa+vJysry9Omf//+pKSkkJeXB0BeXh6DBw/2hBOA7OxsHA4HW7ZsOZVyRERE2p8//cn9PnYspKTQ0NjEzn3ue6FMGH6WDwvzrZO+mX9TUxN33XUX5513HoMGDQLAbrcTHBxMVFSUV9uEhATsdrunzeHhpHl987qjcTqdOJ1Oz7zD4TjZskVERPzHv/4FX33lnr7vPgC+P1BDkwHBAWbiI0N8WJxvnXQPSm5uLl9//TWvvfZaW9ZzVHPnzsVms3leycnJp/1nioiInFYbNsBNN7XMX3QRAG9s2ANAevcuBHTCsSfNTiqgTJs2jaVLl/LJJ5/QrVvLyOLExERcLhfl5eVe7UtKSkhMTPS0+fFVPc3zzW1+bPbs2VRUVHhee/bsOZmyRURE/IPDASNHtszv3AlmMw2NTby23v0dd905nft/xlsVUAzDYNq0abz11lt8/PHHpKameq1PT08nKCiIFStWeJYVFBRQWFhIZmYmAJmZmWzevJnS0lJPm2XLlmG1WklLSzvqz7VYLFitVq+XiIhIu9TUBDZby/ySJdCzJ1XOBqa/+gUVtfVEhgTy837xvqvRD7RqDEpubi6vvPIK77zzDpGRkZ4xIzabjdDQUGw2G1OmTGHGjBlER0djtVqZPn06mZmZjBo1CoCxY8eSlpbGjTfeyLx587Db7dx///3k5uZisVjafg9FRET8SXZ2y/Rdd8Gll1JX38hV8//L9lL34Nj7xvXHFhrkm/r8RKsuMzaZjn4ubOHChdx8882A+0Zt99xzD6+++ipOp5Ps7GyeffZZr9M3u3fvZurUqaxcuZLw8HAmT57MY489RmDgieUlXWYsIiLtUkEB9O/vnu7b1z0PPP7hNuZ/spMISyDP35jOub1jfVjk6dOa7+9Tug+KryigiIhIu1NfD4ff66uhAQIC2GZ3cNkzn1PfaPD3G9PJHnj08ZgdwRm7D4qIiIicAMOAw8dZLlwIAQEcqHLy8LtbqW80GNM/vkOHk9Y66fugiIiIyAl64AHYscM9fdVVcPPNPLJkK//47y4AAswmfje+vw8L9D8KKCIiIqfbk0+63886C958k3e/LPKEk34Jkfzukv70SYj0YYH+RwFFRETkdNq2DWpq3NOff87qHfv5/ZubAZg+ujf3jO3nw+L8lwKKiIjI6XTYzUWX1YTy25fXUd9okNkzhjvG9PFhYf5NAUVEROR0evNNAPakDefWf24A4OK0BJ65/myCAnStyk9RQBERETld7HZ47jkAvql3X2J8/TkpzLk0jZCgAF9W5vcU3URERNqaYcBTT0HXrp5Fj//sRjJSo5k7YTChwQonx6MeFBERkbb2xBNw772e2d9n51LYNZUFVw3yYVHtiwKKiIhIW9q/3yuc/O8f/8ErlfH8elR3esfrUuITpVM8IiIibSknxzNZsGUXj9e67w7bIzbcVxW1SwooIiIibWXXLli3DgDnzPuYsuQ7nA1NdAkLYmxago+La18UUERERNrKtGnu95AQ7hp4NXsP1pJgtfB/U88l3hri29raGQUUERGRtlBQAO+9B8D3f/gz739TCsCzk9LpGRfhy8raJQUUERGRtpCR4Zn8XehgAC4d0pX07l18VVG7poAiIiJyqr76CioqAHj9vr+wZk8lJhPcqVvZnzQFFBERkVM1ebJn8j6T++F/s8bpCcWnQgFFRETkVDz/PGzaBMC/zr4EgBtGpfCbC3r6sKj2TwFFRETkZP3jH/Cb33hmHxlzKxenJfCHKwZhMpl8WFj7p4AiIiJyMn7/e5gyxTObOXUh56cl8fyN6QonbUABRUREpLX+/GeYO9czO+5Xz3DRxem8cNMIhZM2omfxiIiItEZpKcyc6Zk9e/rLHAyzsXB0bwID9P/9bUUBRUREpDUOu9/JuXe+zMEQG+ekRtPVFurDojoeRT0REZETtXAhfP89AP83bCxFITYsgWYevWqQb+vqgBRQRERETsSXX8Itt3hm77s4lwFdrbxxeya943W/k7amUzwiIiLHcvAg3HEHvPSSZ9HFt/2dZyefw8UDEjCbNSj2dFBAERER+SkvvAC33ea1aNrl93HD5LFkD0z0UVGdgwKKiIjIj5WXQ79+7it2DvkmsReTJ8whOKUbz2R2911tnYQCioiICIDLBWvWwOuvw/z5XqvGTFnAzthkwoMDeOGXw3WvkzNAAUVERDo3hwPuvx+eeeaIVS8NG88jY27DFRjE4LNszLt6CAO6Wn1QZOejgCIiIp3TgQMwcSKsWuW1uMkcwFsDLuCNIRdTkXE+/++8Hvy8XzxxkRYfFdo5KaCIiEjns3kzDBnitahx4CD+947HmPude/43F/bkvuz+BOgqHZ/QfVBERKRzOHDAfYv64GCvcGJccQVL3/kvw6/5iyec3HJeKrPHD1A48SH1oIiISMdlGPD55/DYY/Dee0esds57nAmWDLasPghA34QI7srqyyWDu57pSuVHFFBERKTj2bUL7r0X3nzzyHXnn0/jPfeyosdwbnvtK8ABwO0X9mLGxX0JDtTJBX/Q6qPw6aefctlll5GUlITJZOLtt9/2Wm8YBnPmzKFr166EhoaSlZXF9u3bvdqUlZUxadIkrFYrUVFRTJkyhaqqqlPaEREREXbuhMxM6NnzyHBy660Uf1XAkr/9mwsLIg+FE7eHLkvjd+P7K5z4kVb3oFRXVzN06FBuueUWJkyYcMT6efPm8fTTT7N48WJSU1N54IEHyM7OZuvWrYSEhAAwadIkiouLWbZsGfX19fzqV7/itttu45VXXjn1PRIRkc6lshL+/nd44gkoLvZa5bxqIutHX8l/koaQv/sg377s/T/MvxjRjXuz+xEfGXImK5YTYDIMwzjpjU0m3nrrLa688krA3XuSlJTEPffcw7333gtARUUFCQkJLFq0iOuuu45vvvmGtLQ01q9fz4gRIwD44IMPuOSSS9i7dy9JSUnH/bkOhwObzUZFRQVWq65HFxHpVBobYeVKmD0btm1zB5Qf2XRBDg+NvpVNtd7/H242QY+YcC7sF8ftF/Yiwapgcia15vu7Tceg7Nq1C7vdTlZWlmeZzWYjIyODvLw8rrvuOvLy8oiKivKEE4CsrCzMZjNr167lqquuOuJznU4nTqfTM+9wONqybBER8Xf798NHH8G778K//33UJoVdU3lhyHjeHPBzqi1hUOtenhobzoV94zi3VwzDkqOIVyhpF9o0oNjtdgASEhK8lickJHjW2e124uPjvYsIDCQ6OtrT5sfmzp3Lww8/3JalioiIP/vmG3j+edi9G776yj225GhmzOCTn09g1sofKA0KByAlOowJfeMY1TOG83rHEBUWfAYLl7bSLq7imT17NjNmzPDMOxwOkpOTfViRiIi0KacTPv4Y9u6FO++E2tqjt7NY3FfnXHstNX378+r6vfxh6VYICmd4ShRPXjuM7jHhZ7Z2OS3aNKAkJrofPV1SUkLXri3XkJeUlDBs2DBPm9LDng4J0NDQQFlZmWf7H7NYLFgsusWwiEiH0djofihfcTE89RTs2XP0dkOGwG9/ixEaij0rhy8OuNhmr+Tzz/ax6ZWPaDo0inJM/3j+fmM6gQG6CqejaNOAkpqaSmJiIitWrPAEEofDwdq1a5k6dSoAmZmZlJeXk5+fT3p6OgAff/wxTU1NZGRktGU5IiLiDxob3T0iJSXw6qvuga0vv3z0trGx0K8fzrHjWDfxFrbur+WbYgd53x2g5Ok1RzaPCObakcncO7afnjDcwbQ6oFRVVbFjxw7P/K5du9i0aRPR0dGkpKRw11138cc//pE+ffp4LjNOSkryXOkzYMAAxo0bx6233spzzz1HfX0906ZN47rrrjuhK3hERMSP1de7x40ALF8On37qDiU/JToaLrqI2qHD+XLkaP5r7kL+7oNsLDxI3b++8GoaYDbRPzGSwWfZ6BEbzti0BHrGRZzGnRFfavVlxitXruSiiy46YvnkyZNZtGgRhmHw4IMP8vzzz1NeXs7555/Ps88+S9++fT1ty8rKmDZtGkuWLMFsNjNx4kSefvppIiJO7B+aLjMWEfETdrt7AOtLL7lP17zzznE3MbKzqU5JZeOYK1kRchb/3XmAHaVH3qwzyRbC2SldGNA1kmHJXUjv3oXQ4IDTsRdyhrTm+/uU7oPiKwooIiJn2K5dsHEj/Oc/7lM0huE+bfPll0dvHxaGERCAYcB3N09lzcBz2Rgaz3flTnYedFJZ13DEJj1jwxnevQvDU9xhpE98BGY9rK9D8dl9UEREpANYssQ9aNXhgL/9DQICoLDwmJs09OpNbYSVb8Zfw9aUNDZGJbPmuwOUVh66h9X3AGWe9oFmE/27RjKiezQZqdFk9IwhOlyXA0sLBRQRkc6qthaqq+HFF92nap55xj2g9VibnDOK2gaDNZdOYk9lPfZKJx/aelIUeOgUvQHsBnYXARAcaKZvQgS94iIYlGSje0wY3WPC6R4TRkiQTtfIT1NAERHpDKqroagIqqrghRfg7bePeG7NjxWOvoRqVyNfdh/Ip9G9+DwoHkdQqHulEwgGYtyzZhMkR4eRGhtOcpcwEm0hnJ0SxfCULgoiclIUUEREOpqtW6Hs0OmUf/4TvvsOVqw45ia7knqSd9YgVp01iE1JfSmJjD1quwhLIL3iwkmNDSctyUrP2AhS49yhRE8ClrakgCIi0h6tW9cyLqSmBp5+GgIDMbZuxXSUh+c1c1jCwTD44qz+fNg3k/8bOJpGcwANAS1fB5ZAM8lWCz1iwukVF0GPmDB6x0fSOz6CBKtF9xuRM0IBRUTEHzU0uB+KV17unv/sM1hz6EZlxcXgch11s8Ojw87oswCoCIng30PG8lnq2ZTFJJJoDSEu0kJUWDCXWALpaguhf1crA5OsxEdaiLAEKoSIzymgiIicaZWV7h6QVavcl+uC+7TMu+9C4KE/y3V1J/RRa5MHAe6xqZsTe7MmZTCNlhBKzx5F19hI+neNJCU6jImxEdwTE0ZcpHpApH1QQBEROZ2qq+GHH2DlSsjPh0WLfrL3A3D3nBxmX1iUJ4SYMHjp7EuoCQrBCAzCPHQwvZO6kNwljG5dQulvtXBueDC94iI0MFXaPQUUEZG2sG0blJa6e0QWLHCPC6mpOe7g1JeGjaf+0PgPAxNvD/w5+8OjAKgNtOCIiKJPfATduoTSIyacnFj3ANWhyVFEWPQnXDou/esWETkRn3/eclluQwP89a80NTXhamgi4PtdBB0sO+bmFZZwTIbBiyOvZHtsCst7Z+AKCASTiQCziYRIC91jwknvGknP2HB6xkXQPSaMRGuIntArnZICioiIYbjvC7J3r3tQ6vz5GBYLjU0GTYZB8A97j7qZGQj50bKd0d0wgCJrHEv7/wzDBPm90wlM7U5ylzCSo8MY3iWUK6LDSO4SRldbCLbQIN3SXeRHFFBEpGOrqoKGBozPP6f+89XU1jdS62ok7JNlhG8vAKOJgPr6IzYzcfQ/kGuaB6WaTOyM7kZe/1FEhQURHB7KD4NHEhMTSbdDQeT6LqEkR4cREx6sgakiraSAIiLtTmOTQWVdPeU19VSWHqBu916qnA1UV9XQ4/V/0uB0Ud/YRL91K7FWHgTcgSP40Mv2E59bbw7gw77nYgBrUwbzdVJfIkMCiYkIJsoWgWngQM6KjSA52j0o9bIuYdwQGnRmdlqkk1FAERGfMAyDSmcDjtp6KusaqHI2UFlXz/4qF+U1Lipq6ymrdmHZuZ2A0hKqnI1UOxu4IH850eX7AIh01pCxd0urfu6/Rl6OJSiAkKAAzGFhbBr/CyIjQrBawwhNPovo8GBiIizMjIvAGqr7gYj4igKKiLQ5wzAoq3Zhd9RRUVNPRW09+6uc2B11FFfUUVRey9YiB466BsxNjVyw6wsiXDUAjN2+hnPKizEZkOTYR1xN+Qn9zKqwSEwmEyZgX2o/fhh5PmGWQELO6orr+kl0ibAQExXGjRbvHo9L23jfRaRtKKCIyHE5Gxopr6nnQJWLgzUuDlS7OFjd8l5eW4+jtp5qZwMHql0UldfibGgCoO++7zl391eezxqxv5DRO9fRaHLfp+Osyn0nVEN1r76YTRBgNmGy2jDddqv76hazGcaOJSIpydO2+6GXiLRfCiginZijrp7i8jqKKmopLq+jtLKO8pp69lU5+eFgLWXVLsqqXVQ5D7t5mGFgdVYD0KXWwYSvPyGxqcEz/8svP8Rldv9pMWMQ2NR4YsVYLJCZ6Z4ODITp0yEgAIKD4Wc/Izzkx9fLiEhHpoAi0kEYhkFtfSNFh4JGWbWLA1Uuz7SjtgFHnbunw1HXwL5Kpyd4xFUdxFpXBUB4fS3Xb/oAc/Mt2A8xmdwPkbti44fHrSW4qeHIhVdf3XIbd8OASZOgudcjMhL69HH/EBERFFBE/FZZtYviiloOVtdTVuM+lXLw0HtZTb37vdo9oNRR10C1q8HzWBdzUyOD7TsIbXB6Pi++6iC//noFjSbvm371K9vDWeUlp1ZsVhYMHOieNpngkksgLa1lfUJCSzgRETkB+oshcgY1NDZRVuPu2Sg7NIbjQJWT3QdqKHHUsb/KSUVtPfsqnRysOfLeHAAj93xNYuUBugBdgOxv80iuKMGEO52YTSYGFW8/uQJjYtzvhuE+3XL++Udvl54OF13knjYfGgciItKGFFBEToFhGFQ5GyirdlHicF+lUlblpKzaxf5qF2WHgsj+aueh3o6jh47DZX+7mvMc+zAbBrdueJsAkwmzyR08uhwsbX2Rh/dkNDXBuHEwZIh3m9BQuPxyCAtr/eeLiJwGCigiR9HQ2MS+KicHqlyUOOoocTj5obyGEoeTfZXuV/MAUldj03E/L6CpkUhnNVG4z4CMKdlGeukOQoMDCA0KYPSHrxLQ2Ii58ShjN37K6NEt08HBMG2ad09Gly6QkaFxHSLSLimgSKdS62pkf5Xz0MvF/ionBw6b3l/lpLiijr0Ha2lsMo7/gUCoq47etfuJCgsmNsJC75p9jNq4EkuQmZDAAEIbnJz14butKzQoyD2o1GRyj+0YN65lXXAwDBjgvsJFRKSDUkCRDqGxyWCb3cGu/dUc8ISNltDRvKzGdYKXvAKBZhPDq4vp1VBJTEQw0eHBZOZ9QJSjjOAAM0GBJoKbGglZ9cnJF37XXS09HEOHwsUXu8NJXNzJf6aISAeggCLtgmEYHKypp7iilvIa9y3Qdx+oZntpFUXltRTYK3HUndjpEUugma4hJi4u/IJYcyORIYEM+XoNiXt2Emh2BxNLYACBewsxlZWdeJGxsS3TLhdcdx307Omeb76yZcCAljbqARER+UkKKOI3al2N7D1YQ2FZDXvKathzsLZluqyG6uP0fkRYAhmQGEH21s9Iqi4jwhJIWHAAVqOe1FdexBTkfqS9CTAVFbWuuOZLaAGiouDWW73XX3ABpKa27jNFROQnKaDIGWMYBhW19RSW1bC9pIrvD1Szp+xQIDlYy75K5zG3D3PV0tUCwyv2cu53G4kIDiAmIpjk77YSt/ZzDLMZU9PxB6x6SUiAQYNa5u+4wz3Go1lwMJx3nvsupyIicsYooMhpYxgGm/aUs7XYQf7ug3z67X72Vx07hERaAkmODqNPSCMDGyoYWLydnlvziflyPcHf7Tzmtl7hJDQUrrrqsJUm9309zjuvZVmXLtBdT2wREfFHCijSpgzD4Ku9FSxe/T153x2guKLuiDbR4cH0TYggNTaClOgw+taXk3pgL/GRFsLfX4Lpk6/gs8+O/8NuvdV9i3RwDyy9+Waw2dzTh48HERGRdkcBRdrMO5t+4LH3t3mFkuBAM+f2iqFnbAQXpyUwLDmKUPsP7gCyuxTumw87j9EzEhcHTqf7wXHdurlDSPPpFt3fQ0Skw1JAkVNiGAbvbCrizS9+4NNv9wHu3DB+UCK/rd9Fv9LvCTpohv/7GDZudG9UXHz0Dxs82P0eGAh33w1jxrQ8TE5ERDoVBRQ5aZ9t38dD725h575qz7LxfWP467a3Cb7hT8f/gAsucA9Cvfhi9+maLl1OY7UiItKeKKDISflX3vc88M4WwH3fkBvOTuTOd5+hy58WHdn4hhvc72YzTJ3qHsCamgpW65krWERE2hUFFGm11zfs8YSTsU2lPGlsJ/wXc70bdesGr70G556rsSIiItJqPn1G+vz58+nRowchISFkZGSwbt06X5YjJ6CxyeCvy7djMppY8u7DPP/4LYTPOyycDBoEO3bAnj3uS3oVTkRE5CT4LKD8+9//ZsaMGTz44INs3LiRoUOHkp2dTWnpSTxOXs6Y/8vfyw/ltbzy+gMM/mZ9y4oBA2DtWti8GXr18l2BIiLSIZgMwzixR7a2sYyMDEaOHMnf/vY3AJqamkhOTmb69On87ne/O+a2DocDm81GRUUFVo1jOG2amgxq6hupqmugsq6eTXvK+cuHBcx/djrpRdtaGtbUuMeViIiIHENrvr99MgbF5XKRn5/P7NmzPcvMZjNZWVnk5eUd0d7pdOJ0ttyB1OFwnJ7CPvkE/vEPr0X1jU3sq3RSW99IfWMT9Q0GDU0GTYaBAWDAoSmMQ9PNkc/zfmhZcxI0jOalzdsf3rZlYUt747B1R7b1fPZRlv94O+OwRj+uv6WN93bNAoAPd6zD5jx01U5oKFRVuQe/ioiItCGfBJT9+/fT2NhIQkKC1/KEhAS2bdt2RPu5c+fy8MMPn/7Ctm+Hl17yWhQE6E4cR3HBBbBypcaYiIjIadEuruKZPXs2M2bM8Mw7HA6Sk5Pb/geNGgV//jPlNS5eXbeHA9XuXpsuYcEkWEMIDQ4gJNBMUICZALMJk8n9/WzGPWECzCa8pk2Hpk0mMB/6MjeZOLSsed79bj70Xe9ef2Tb5ihgOuxzaV7v9Xk0b32oc6OlBg77rKMu+9F8cICZwACT57MB9+XBN92kcCIiIqeNTwJKbGwsAQEBlJSUeC0vKSkhMTHxiPYWiwXLmXia7JAhNAwcxJ2LN7Bq4D6iw4OZc2kalw9NwmzWl7GIiMiZ4pPBA8HBwaSnp7NixQrPsqamJlasWEFmZqYvSvJ4bf0eVh26ZfsLN6Vz5dlnKZyIiIicYT47xTNjxgwmT57MiBEjOOecc3jqqaeorq7mV7/6la9KAuCDr+0A3H5hL9K7R/u0FhERkc7KZwHl2muvZd++fcyZMwe73c6wYcP44IMPjhg4eyaVVbvI++4AANeM6OazOkRERDo7nw6SnTZtGtOmTfNlCV62FjlobDJIsFroGRvu63JEREQ6Ld3A4jA1rgYAkqJCva9aERERkTNKAeUwNa5GAMKD28XV1yIiIh2WAsphqg/1oIQFB/i4EhERkc5NXQWHGZhkY/ro3vSM0/gTERERX1JAOcyw5CiGJUf5ugwREZFOT6d4RERExO8ooIiIiIjfUUARERERv6OAIiIiIn5HAUVERET8jgKKiIiI+B0FFBEREfE7CigiIiLidxRQRERExO8ooIiIiIjfUUARERERv6OAIiIiIn5HAUVERET8Trt8mrFhGAA4HA4fVyIiIiInqvl7u/l7/FjaZUCprKwEIDk52ceViIiISGtVVlZis9mO2cZknEiM8TNNTU0UFRURGRmJyWRq0892OBwkJyezZ88erFZrm362P9D+tX8dfR+1f+1fR9/Hjr5/cPr20TAMKisrSUpKwmw+9iiTdtmDYjab6dat22n9GVartcP+wwPtX0fQ0fdR+9f+dfR97Oj7B6dnH4/Xc9JMg2RFRETE7yigiIiIiN9RQPkRi8XCgw8+iMVi8XUpp4X2r/3r6Puo/Wv/Ovo+dvT9A//Yx3Y5SFZEREQ6NvWgiIiIiN9RQBERERG/o4AiIiIifkcBRURERPyOAsph5s+fT48ePQgJCSEjI4N169b5uqSTMnfuXEaOHElkZCTx8fFceeWVFBQUeLX5+c9/jslk8nrdfvvtPqq49R566KEj6u/fv79nfV1dHbm5ucTExBAREcHEiRMpKSnxYcWt06NHjyP2z2QykZubC7S/4/fpp59y2WWXkZSUhMlk4u233/ZabxgGc+bMoWvXroSGhpKVlcX27du92pSVlTFp0iSsVitRUVFMmTKFqqqqM7gXx3asfayvr2fWrFkMHjyY8PBwkpKSuOmmmygqKvL6jKMd98cee+wM78nRHe8Y3nzzzUfUPm7cOK827fkYAkf9nTSZTDz++OOeNv56DE/ke+FE/m4WFhaSk5NDWFgY8fHxzJw5k4aGhtNSswLKIf/+97+ZMWMGDz74IBs3bmTo0KFkZ2dTWlrq69JabdWqVeTm5rJmzRqWLVtGfX09Y8eOpbq62qvdrbfeSnFxsec1b948H1V8cgYOHOhV/+eff+5Zd/fdd7NkyRLeeOMNVq1aRVFRERMmTPBhta2zfv16r31btmwZANdcc42nTXs6ftXV1QwdOpT58+cfdf28efN4+umnee6551i7di3h4eFkZ2dTV1fnaTNp0iS2bNnCsmXLWLp0KZ9++im33XbbmdqF4zrWPtbU1LBx40YeeOABNm7cyJtvvklBQQGXX375EW0feeQRr+M6ffr0M1H+cR3vGAKMGzfOq/ZXX33Va317PoaA174VFxfzj3/8A5PJxMSJE73a+eMxPJHvheP93WxsbCQnJweXy8Xq1atZvHgxixYtYs6cOaenaEMMwzCMc845x8jNzfXMNzY2GklJScbcuXN9WFXbKC0tNQBj1apVnmUXXnihceedd/quqFP04IMPGkOHDj3quvLyciMoKMh44403PMu++eYbAzDy8vLOUIVt68477zR69eplNDU1GYbRvo8fYLz11lue+aamJiMxMdF4/PHHPcvKy8sNi8VivPrqq4ZhGMbWrVsNwFi/fr2nzfvvv2+YTCbjhx9+OGO1n6gf7+PRrFu3zgCM3bt3e5Z1797dePLJJ09vcW3gaPs3efJk44orrvjJbTriMbziiiuM0aNHey1rL8fwx98LJ/J387333jPMZrNht9s9bRYsWGBYrVbD6XS2eY3qQQFcLhf5+flkZWV5lpnNZrKyssjLy/NhZW2joqICgOjoaK/lL7/8MrGxsQwaNIjZs2dTU1Pji/JO2vbt20lKSqJnz55MmjSJwsJCAPLz86mvr/c6nv379yclJaVdHk+Xy8VLL73ELbfc4vVwzPZ+/Jrt2rULu93udbxsNhsZGRme45WXl0dUVBQjRozwtMnKysJsNrN27dozXnNbqKiowGQyERUV5bX8scceIyYmhrPPPpvHH3/8tHWfnw4rV64kPj6efv36MXXqVA4cOOBZ19GOYUlJCf/5z3+YMmXKEevawzH88ffCifzdzMvLY/DgwSQkJHjaZGdn43A42LJlS5vX2C4fFtjW9u/fT2Njo9d/dICEhAS2bdvmo6raRlNTE3fddRfnnXcegwYN8iz/5S9/Sffu3UlKSuKrr75i1qxZFBQU8Oabb/qw2hOXkZHBokWL6NevH8XFxTz88MP87Gc/4+uvv8ZutxMcHHzEH/6EhATsdrtvCj4Fb7/9NuXl5dx8882eZe39+B2u+Zgc7feveZ3dbic+Pt5rfWBgINHR0e3ymNbV1TFr1iyuv/56rwex3XHHHQwfPpzo6GhWr17N7NmzKS4u5oknnvBhtSdm3LhxTJgwgdTUVHbu3Mnvf/97xo8fT15eHgEBAR3uGC5evJjIyMgjTh23h2N4tO+FE/m7abfbj/p72ryurSmgdHC5ubl8/fXXXuMzAK/zvoMHD6Zr166MGTOGnTt30qtXrzNdZquNHz/eMz1kyBAyMjLo3r07r7/+OqGhoT6srO29+OKLjB8/nqSkJM+y9n78OrP6+np+8YtfYBgGCxYs8Fo3Y8YMz/SQIUMIDg7mN7/5DXPnzvX726pfd911nunBgwczZMgQevXqxcqVKxkzZowPKzs9/vGPfzBp0iRCQkK8lreHY/hT3wv+Rqd4gNjYWAICAo4YrVxSUkJiYqKPqjp106ZNY+nSpXzyySd069btmG0zMjIA2LFjx5korc1FRUXRt29fduzYQWJiIi6Xi/Lycq827fF47t69m+XLl/PrX//6mO3a8/FrPibH+v1LTEw8YsB6Q0MDZWVl7eqYNoeT3bt3s2zZsuM+xj4jI4OGhga+//77M1NgG+rZsyexsbGef5Md5RgCfPbZZxQUFBz39xL87xj+1PfCifzdTExMPOrvafO6tqaAAgQHB5Oens6KFSs8y5qamlixYgWZmZk+rOzkGIbBtGnTeOutt/j4449JTU097jabNm0CoGvXrqe5utOjqqqKnTt30rVrV9LT0wkKCvI6ngUFBRQWFra747lw4ULi4+PJyck5Zrv2fPxSU1NJTEz0Ol4Oh4O1a9d6jldmZibl5eXk5+d72nz88cc0NTV5wpm/aw4n27dvZ/ny5cTExBx3m02bNmE2m484NdIe7N27lwMHDnj+TXaEY9jsxRdfJD09naFDhx63rb8cw+N9L5zI383MzEw2b97sFTSbg3ZaWtppKVoMw3jttdcMi8ViLFq0yNi6datx2223GVFRUV6jlduLqVOnGjabzVi5cqVRXFzsedXU1BiGYRg7duwwHnnkEWPDhg3Grl27jHfeecfo2bOnccEFF/i48hN3zz33GCtXrjR27dpl/Pe//zWysrKM2NhYo7S01DAMw7j99tuNlJQU4+OPPzY2bNhgZGZmGpmZmT6uunUaGxuNlJQUY9asWV7L2+Pxq6ysNL744gvjiy++MADjiSeeML744gvPFSyPPfaYERUVZbzzzjvGV199ZVxxxRVGamqqUVtb6/mMcePGGWeffbaxdu1a4/PPPzf69OljXH/99b7apSMcax9dLpdx+eWXG926dTM2bdrk9XvZfPXD6tWrjSeffNLYtGmTsXPnTuOll14y4uLijJtuusnHe+Z2rP2rrKw07r33XiMvL8/YtWuXsXz5cmP48OFGnz59jLq6Os9ntOdj2KyiosIICwszFixYcMT2/nwMj/e9YBjH/7vZ0NBgDBo0yBg7dqyxadMm44MPPjDi4uKM2bNnn5aaFVAO88wzzxgpKSlGcHCwcc455xhr1qzxdUknBTjqa+HChYZhGEZhYaFxwQUXGNHR0YbFYjF69+5tzJw506ioqPBt4a1w7bXXGl27djWCg4ONs846y7j22muNHTt2eNbX1tYav/3tb40uXboYYWFhxlVXXWUUFxf7sOLW+/DDDw3AKCgo8FreHo/fJ598ctR/k5MnTzYMw32p8QMPPGAkJCQYFovFGDNmzBH7feDAAeP66683IiIiDKvVavzqV78yKisrfbA3R3esfdy1a9dP/l5+8sknhmEYRn5+vpGRkWHYbDYjJCTEGDBggPHoo496fcH70rH2r6amxhg7dqwRFxdnBAUFGd27dzduvfXWI/4Hrz0fw2Z///vfjdDQUKO8vPyI7f35GB7ve8EwTuzv5vfff2+MHz/eCA0NNWJjY4177rnHqK+vPy01mw4VLiIiIuI3NAZFRERE/I4CioiIiPgdBRQRERHxOwooIiIi4ncUUERERMTvKKCIiIiI31FAEREREb+jgCIiIiJ+RwFFRERE/I4CioiIiPgdBRQRERHxOwooIiIi4nf+f8ktKyQZrNT6AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "def f(x):\n",
    "    return x**2*np.exp(-x**2)\n",
    "x = np.linspace ( start = 0.    # lower limit\n",
    "                , stop = 200      # upper limit\n",
    "                , num = 2827      # generate 51 points between 0 and 3\n",
    "                )\n",
    "# x = x.reshape(2827,1)\n",
    "y = pred1    # This is already vectorized, that is, y will be a vector!\n",
    "plt.plot(x, y)\n",
    "yy = new_numpy\n",
    "plt.plot(x, yy, 'r-')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
