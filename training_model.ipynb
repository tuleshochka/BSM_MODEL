{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import json\n",
    "    import os\n",
    "    \n",
    "    import pandas as  pd\n",
    "    import spacy\n",
    "    \n",
    "    import seaborn as sns\n",
    "    import string\n",
    "\n",
    "    from tqdm import tqdm\n",
    "    from textblob import TextBlob\n",
    "    \n",
    "    from nltk.corpus import stopwords\n",
    "    import nltk\n",
    "    from nltk.stem import WordNetLemmatizer\n",
    "    from nltk import word_tokenize\n",
    "    import re\n",
    "    \n",
    "    \n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    from sklearn.feature_extraction.text import CountVectorizer\n",
    "    from sklearn.feature_extraction.text import TfidfTransformer\n",
    "    from sklearn.naive_bayes import MultinomialNB\n",
    "    from sklearn.pipeline import Pipeline\n",
    "    \n",
    "    \n",
    "    from sklearn.preprocessing import FunctionTransformer\n",
    "    from sklearn.base import BaseEstimator, TransformerMixin\n",
    "    from sklearn.pipeline import FeatureUnion\n",
    "    from sklearn.feature_extraction import DictVectorizer\n",
    "    \n",
    "    import swifter\n",
    "    \n",
    "    tqdm.pandas()\n",
    "except Exception as e:\n",
    "    print(\"Error : {} \".format(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "flight_rasp = pd.read_csv(\"flight_rasp_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_table = pd.read_csv(\"final_table_v2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "flight_rasp = flight_rasp.join(final_table['sum_bsm'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "flight_rasp_v2 = flight_rasp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "flight_rasp_v2['t_st'] = pd.to_datetime(flight_rasp_v2['t_st'], \n",
    "format = '%Y-%m-%d %H:%M:%S', \n",
    "errors = 'coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 28267 entries, 0 to 28266\n",
      "Data columns (total 10 columns):\n",
      " #   Column                Non-Null Count  Dtype         \n",
      "---  ------                --------------  -----         \n",
      " 0   i_id                  28267 non-null  float64       \n",
      " 1   departure_terminal    28267 non-null  object        \n",
      " 2   checkin_terminal      28267 non-null  object        \n",
      " 3   airline_grouped_hash  28267 non-null  object        \n",
      " 4   cco_hash              28267 non-null  object        \n",
      " 5   flt_hash              28267 non-null  object        \n",
      " 6   t_st                  28267 non-null  datetime64[ns]\n",
      " 7   m_city_rus1           28267 non-null  object        \n",
      " 8   m_city_rus2           28267 non-null  object        \n",
      " 9   config                28267 non-null  int64         \n",
      "dtypes: datetime64[ns](1), float64(1), int64(1), object(7)\n",
      "memory usage: 2.2+ MB\n"
     ]
    }
   ],
   "source": [
    "flight_rasp_v2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "flight_rasp_v2['t_st_year'] = flight_rasp_v2['t_st'].dt.year\n",
    "flight_rasp_v2['t_st_month'] = flight_rasp_v2['t_st'].dt.month\n",
    "flight_rasp_v2['t_st_day'] = flight_rasp_v2['t_st'].dt.day\n",
    "flight_rasp_v2['t_st_hour'] = flight_rasp_v2['t_st'].dt.hour\n",
    "flight_rasp_v2['t_st_minute'] = flight_rasp_v2['t_st'].dt.minute\n",
    "flight_rasp_v2['t_st_second'] = flight_rasp_v2['t_st'].dt.second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flight_rasp_v2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "flight_rasp_v2 = flight_rasp_v2.drop(['t_st'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(flight_rasp_v2['departure_terminal'])\n",
    "flight_rasp_v2['departure_terminal'] = le.transform(flight_rasp_v2['departure_terminal'])\n",
    "\n",
    "le.fit(flight_rasp_v2['checkin_terminal'])\n",
    "flight_rasp_v2['checkin_terminal'] = le.transform(flight_rasp_v2['checkin_terminal'])\n",
    "\n",
    "le.fit(flight_rasp_v2['airline_grouped_hash'])\n",
    "flight_rasp_v2['airline_grouped_hash'] = le.transform(flight_rasp_v2['airline_grouped_hash'])\n",
    "\n",
    "\n",
    "le.fit(flight_rasp_v2['cco_hash'])\n",
    "flight_rasp_v2['cco_hash'] = le.transform(flight_rasp_v2['cco_hash'])\n",
    "\n",
    "\n",
    "le.fit(flight_rasp_v2['flt_hash'])\n",
    "flight_rasp_v2['flt_hash'] = le.transform(flight_rasp_v2['flt_hash'])\n",
    "\n",
    "le.fit(flight_rasp_v2['m_city_rus1'])\n",
    "flight_rasp_v2['m_city_rus1'] = le.transform(flight_rasp_v2['m_city_rus1'])\n",
    "\n",
    "le.fit(flight_rasp_v2['m_city_rus2'])\n",
    "flight_rasp_v2['m_city_rus2'] = le.transform(flight_rasp_v2['m_city_rus2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>departure_terminal</th>\n",
       "      <th>checkin_terminal</th>\n",
       "      <th>airline_grouped_hash</th>\n",
       "      <th>cco_hash</th>\n",
       "      <th>flt_hash</th>\n",
       "      <th>m_city_rus1</th>\n",
       "      <th>m_city_rus2</th>\n",
       "      <th>config</th>\n",
       "      <th>t_st_year</th>\n",
       "      <th>t_st_month</th>\n",
       "      <th>t_st_day</th>\n",
       "      <th>t_st_hour</th>\n",
       "      <th>t_st_minute</th>\n",
       "      <th>t_st_second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>34</td>\n",
       "      <td>265</td>\n",
       "      <td>0</td>\n",
       "      <td>109</td>\n",
       "      <td>156</td>\n",
       "      <td>2023</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>227</td>\n",
       "      <td>0</td>\n",
       "      <td>114</td>\n",
       "      <td>202</td>\n",
       "      <td>2023</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>34</td>\n",
       "      <td>169</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>158</td>\n",
       "      <td>2023</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>34</td>\n",
       "      <td>385</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>156</td>\n",
       "      <td>2023</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>34</td>\n",
       "      <td>326</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>196</td>\n",
       "      <td>2023</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   departure_terminal  checkin_terminal  airline_grouped_hash  cco_hash  \\\n",
       "0                   0                 0                    21        34   \n",
       "1                   1                 1                    11        11   \n",
       "2                   0                 0                    21        34   \n",
       "3                   0                 0                    21        34   \n",
       "4                   0                 0                    21        34   \n",
       "\n",
       "   flt_hash  m_city_rus1  m_city_rus2  config  t_st_year  t_st_month  \\\n",
       "0       265            0          109     156       2023           7   \n",
       "1       227            0          114     202       2023           7   \n",
       "2       169            0           25     158       2023           7   \n",
       "3       385            0           41     156       2023           7   \n",
       "4       326            0            1     196       2023           7   \n",
       "\n",
       "   t_st_day  t_st_hour  t_st_minute  t_st_second  \n",
       "0         8          0            5            0  \n",
       "1         8          0            5            0  \n",
       "2         8          0           10            0  \n",
       "3         8          0           10            0  \n",
       "4         8          0           15            0  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flight_rasp_v2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = flight_rasp_v2.drop('sum_bsm', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "flight_rasp_v2.to_csv(\"final_table_with_x_y.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = flight_rasp_v2['sum_bsm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test =  train_test_split(X,y,test_size = 0.1, random_state= 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "25440/25440 [==============================] - 81s 3ms/step - loss: 7299.3315 - accuracy: 0.0010\n",
      "Epoch 2/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 6366.3105 - accuracy: 8.2547e-04\n",
      "Epoch 3/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 5866.7837 - accuracy: 8.2547e-04\n",
      "Epoch 4/200\n",
      "25440/25440 [==============================] - 80s 3ms/step - loss: 4402.3628 - accuracy: 0.0017\n",
      "Epoch 5/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 2979.5894 - accuracy: 0.0300\n",
      "Epoch 6/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 2129.4075 - accuracy: 0.0373\n",
      "Epoch 7/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 1814.5651 - accuracy: 0.0399\n",
      "Epoch 8/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 1588.6257 - accuracy: 0.0467\n",
      "Epoch 9/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 1785.3636 - accuracy: 0.0458\n",
      "Epoch 10/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 1571.1851 - accuracy: 0.0381\n",
      "Epoch 11/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 2301.8801 - accuracy: 0.0073\n",
      "Epoch 12/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 2420.6875 - accuracy: 0.0032\n",
      "Epoch 13/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 1580.2412 - accuracy: 0.0094\n",
      "Epoch 14/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 1395.5371 - accuracy: 0.0234\n",
      "Epoch 15/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 1330.7543 - accuracy: 0.0402\n",
      "Epoch 16/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 1278.6769 - accuracy: 0.0463\n",
      "Epoch 17/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 1191.4514 - accuracy: 0.0517\n",
      "Epoch 18/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 1256.4065 - accuracy: 0.0484\n",
      "Epoch 19/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 1116.4705 - accuracy: 0.0403\n",
      "Epoch 20/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 1214.2892 - accuracy: 0.0430\n",
      "Epoch 21/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 1094.4706 - accuracy: 0.0626\n",
      "Epoch 22/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 1074.5765 - accuracy: 0.0899\n",
      "Epoch 23/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 1066.2466 - accuracy: 0.0746\n",
      "Epoch 24/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 1023.3251 - accuracy: 0.0860\n",
      "Epoch 25/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 968.9645 - accuracy: 0.0800\n",
      "Epoch 26/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 980.6009 - accuracy: 0.0742\n",
      "Epoch 27/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 957.3897 - accuracy: 0.0903\n",
      "Epoch 28/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 989.1537 - accuracy: 0.0728\n",
      "Epoch 29/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 988.1901 - accuracy: 0.0691\n",
      "Epoch 30/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 961.7399 - accuracy: 0.0615\n",
      "Epoch 31/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 922.6703 - accuracy: 0.0842\n",
      "Epoch 32/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 888.1223 - accuracy: 0.0783\n",
      "Epoch 33/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 928.5718 - accuracy: 0.0739\n",
      "Epoch 34/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 885.5641 - accuracy: 0.0702\n",
      "Epoch 35/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 871.3610 - accuracy: 0.0849\n",
      "Epoch 36/200\n",
      "25440/25440 [==============================] - 81s 3ms/step - loss: 843.2023 - accuracy: 0.0830\n",
      "Epoch 37/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 858.1230 - accuracy: 0.0893\n",
      "Epoch 38/200\n",
      "25440/25440 [==============================] - 82s 3ms/step - loss: 863.4796 - accuracy: 0.0833\n",
      "Epoch 39/200\n",
      "25440/25440 [==============================] - 80s 3ms/step - loss: 881.1100 - accuracy: 0.0941\n",
      "Epoch 40/200\n",
      "25440/25440 [==============================] - 80s 3ms/step - loss: 837.9628 - accuracy: 0.0890\n",
      "Epoch 41/200\n",
      "25440/25440 [==============================] - 82s 3ms/step - loss: 816.4670 - accuracy: 0.0936\n",
      "Epoch 42/200\n",
      "25440/25440 [==============================] - 81s 3ms/step - loss: 823.9481 - accuracy: 0.0891\n",
      "Epoch 43/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 856.7576 - accuracy: 0.0931\n",
      "Epoch 44/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 802.1364 - accuracy: 0.0904\n",
      "Epoch 45/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 792.6593 - accuracy: 0.1043\n",
      "Epoch 46/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 800.0062 - accuracy: 0.0927\n",
      "Epoch 47/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 799.2049 - accuracy: 0.0913\n",
      "Epoch 48/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 781.1762 - accuracy: 0.1080\n",
      "Epoch 49/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 833.2914 - accuracy: 0.0879\n",
      "Epoch 50/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 766.4538 - accuracy: 0.0897\n",
      "Epoch 51/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 818.3594 - accuracy: 0.0873\n",
      "Epoch 52/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 753.7775 - accuracy: 0.0906\n",
      "Epoch 53/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 767.7172 - accuracy: 0.0991\n",
      "Epoch 54/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 762.1992 - accuracy: 0.0945\n",
      "Epoch 55/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 773.6005 - accuracy: 0.0866\n",
      "Epoch 56/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 745.6154 - accuracy: 0.1003\n",
      "Epoch 57/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 734.7095 - accuracy: 0.0931\n",
      "Epoch 58/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 755.5883 - accuracy: 0.1001\n",
      "Epoch 59/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 771.9006 - accuracy: 0.1000\n",
      "Epoch 60/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 753.9242 - accuracy: 0.0995\n",
      "Epoch 61/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 737.9063 - accuracy: 0.1010\n",
      "Epoch 62/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 735.8909 - accuracy: 0.1011\n",
      "Epoch 63/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 719.7801 - accuracy: 0.1066\n",
      "Epoch 64/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 710.3139 - accuracy: 0.0886\n",
      "Epoch 65/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 747.9877 - accuracy: 0.0882\n",
      "Epoch 66/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 717.4454 - accuracy: 0.1104\n",
      "Epoch 67/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 716.8923 - accuracy: 0.1086\n",
      "Epoch 68/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 718.0740 - accuracy: 0.1006\n",
      "Epoch 69/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 699.2307 - accuracy: 0.0991\n",
      "Epoch 70/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 702.4732 - accuracy: 0.0976\n",
      "Epoch 71/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 695.3763 - accuracy: 0.0819\n",
      "Epoch 72/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 682.4359 - accuracy: 0.0720\n",
      "Epoch 73/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 687.3498 - accuracy: 0.0812\n",
      "Epoch 74/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 688.2953 - accuracy: 0.0783\n",
      "Epoch 75/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 674.2369 - accuracy: 0.0726\n",
      "Epoch 76/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 726.4047 - accuracy: 0.0732\n",
      "Epoch 77/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 851.9599 - accuracy: 0.0524\n",
      "Epoch 78/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 692.3318 - accuracy: 0.0600\n",
      "Epoch 79/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 696.0219 - accuracy: 0.0642\n",
      "Epoch 80/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 729.6103 - accuracy: 0.0831\n",
      "Epoch 81/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 729.9790 - accuracy: 0.0820\n",
      "Epoch 82/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 715.0994 - accuracy: 0.0855\n",
      "Epoch 83/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 687.8633 - accuracy: 0.0911\n",
      "Epoch 84/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 670.2429 - accuracy: 0.0936\n",
      "Epoch 85/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 664.5430 - accuracy: 0.0903\n",
      "Epoch 86/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 678.6720 - accuracy: 0.0811\n",
      "Epoch 87/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 664.5031 - accuracy: 0.0836\n",
      "Epoch 88/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 646.4523 - accuracy: 0.0841\n",
      "Epoch 89/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 650.0828 - accuracy: 0.0842\n",
      "Epoch 90/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 631.0941 - accuracy: 0.0932\n",
      "Epoch 91/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 669.7874 - accuracy: 0.0951\n",
      "Epoch 92/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 689.6900 - accuracy: 0.0646\n",
      "Epoch 93/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 649.2728 - accuracy: 0.0793\n",
      "Epoch 94/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 649.0337 - accuracy: 0.0739\n",
      "Epoch 95/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 649.2311 - accuracy: 0.0777\n",
      "Epoch 96/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 655.3625 - accuracy: 0.0765\n",
      "Epoch 97/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 634.3276 - accuracy: 0.0683\n",
      "Epoch 98/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 635.5403 - accuracy: 0.0776\n",
      "Epoch 99/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 715.1676 - accuracy: 0.0840\n",
      "Epoch 100/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 720.2393 - accuracy: 0.0780\n",
      "Epoch 101/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 625.1633 - accuracy: 0.0951\n",
      "Epoch 102/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 632.7809 - accuracy: 0.0967\n",
      "Epoch 103/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 737.1765 - accuracy: 0.0627\n",
      "Epoch 104/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 775.4115 - accuracy: 0.0360\n",
      "Epoch 105/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 692.1591 - accuracy: 0.0643\n",
      "Epoch 106/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 668.9067 - accuracy: 0.0901\n",
      "Epoch 107/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 711.7200 - accuracy: 0.0831\n",
      "Epoch 108/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 622.4966 - accuracy: 0.0938\n",
      "Epoch 109/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 649.6332 - accuracy: 0.0724\n",
      "Epoch 110/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 665.9749 - accuracy: 0.0713\n",
      "Epoch 111/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 652.5621 - accuracy: 0.1055\n",
      "Epoch 112/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 626.7177 - accuracy: 0.1074\n",
      "Epoch 113/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 637.2579 - accuracy: 0.0960\n",
      "Epoch 114/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 630.8950 - accuracy: 0.1050\n",
      "Epoch 115/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 631.5698 - accuracy: 0.0931\n",
      "Epoch 116/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 622.3680 - accuracy: 0.0945\n",
      "Epoch 117/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 628.0489 - accuracy: 0.0977\n",
      "Epoch 118/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 629.6873 - accuracy: 0.1061\n",
      "Epoch 119/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 616.3362 - accuracy: 0.0917\n",
      "Epoch 120/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 637.0826 - accuracy: 0.0921\n",
      "Epoch 121/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 622.0844 - accuracy: 0.0896\n",
      "Epoch 122/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 677.4949 - accuracy: 0.0607\n",
      "Epoch 123/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 628.0001 - accuracy: 0.0785\n",
      "Epoch 124/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 622.0334 - accuracy: 0.0921\n",
      "Epoch 125/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 605.9919 - accuracy: 0.0962\n",
      "Epoch 126/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 655.2007 - accuracy: 0.1054\n",
      "Epoch 127/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 622.0173 - accuracy: 0.1003\n",
      "Epoch 128/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 612.3083 - accuracy: 0.0909\n",
      "Epoch 129/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 638.3846 - accuracy: 0.0941\n",
      "Epoch 130/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 606.9824 - accuracy: 0.1098\n",
      "Epoch 131/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 697.2025 - accuracy: 0.1040\n",
      "Epoch 132/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 639.8352 - accuracy: 0.0965\n",
      "Epoch 133/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 609.0336 - accuracy: 0.0991\n",
      "Epoch 134/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 649.5740 - accuracy: 0.0941\n",
      "Epoch 135/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 682.9102 - accuracy: 0.0899\n",
      "Epoch 136/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 635.8187 - accuracy: 0.0948\n",
      "Epoch 137/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 583.5616 - accuracy: 0.1055\n",
      "Epoch 138/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 615.6997 - accuracy: 0.1077\n",
      "Epoch 139/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 665.8414 - accuracy: 0.1028\n",
      "Epoch 140/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 626.1148 - accuracy: 0.0964\n",
      "Epoch 141/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 603.2374 - accuracy: 0.0965\n",
      "Epoch 142/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 591.4620 - accuracy: 0.1017\n",
      "Epoch 143/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 645.4407 - accuracy: 0.1020\n",
      "Epoch 144/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 622.5457 - accuracy: 0.1082\n",
      "Epoch 145/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 599.8239 - accuracy: 0.1122\n",
      "Epoch 146/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 618.9781 - accuracy: 0.1039\n",
      "Epoch 147/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 625.1838 - accuracy: 0.1057\n",
      "Epoch 148/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 629.9108 - accuracy: 0.1010\n",
      "Epoch 149/200\n",
      "25440/25440 [==============================] - 80s 3ms/step - loss: 633.3578 - accuracy: 0.1022\n",
      "Epoch 150/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 616.1545 - accuracy: 0.1100\n",
      "Epoch 151/200\n",
      "25440/25440 [==============================] - 80s 3ms/step - loss: 622.9935 - accuracy: 0.1079\n",
      "Epoch 152/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 732.2053 - accuracy: 0.0969\n",
      "Epoch 153/200\n",
      "25440/25440 [==============================] - 80s 3ms/step - loss: 602.5860 - accuracy: 0.1096\n",
      "Epoch 154/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 605.1959 - accuracy: 0.1049\n",
      "Epoch 155/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 619.5474 - accuracy: 0.1031\n",
      "Epoch 156/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 617.8448 - accuracy: 0.1050\n",
      "Epoch 157/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 856.2426 - accuracy: 0.0833\n",
      "Epoch 158/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 661.2139 - accuracy: 0.0933\n",
      "Epoch 159/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 609.5616 - accuracy: 0.0862\n",
      "Epoch 160/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 584.9213 - accuracy: 0.0902\n",
      "Epoch 161/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 602.3000 - accuracy: 0.0847\n",
      "Epoch 162/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 678.8541 - accuracy: 0.0861\n",
      "Epoch 163/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 653.8954 - accuracy: 0.0805\n",
      "Epoch 164/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 755.5228 - accuracy: 0.0765\n",
      "Epoch 165/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 671.3964 - accuracy: 0.0905\n",
      "Epoch 166/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 630.6631 - accuracy: 0.1020\n",
      "Epoch 167/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 592.8935 - accuracy: 0.1042\n",
      "Epoch 168/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 606.9235 - accuracy: 0.1088\n",
      "Epoch 169/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 603.9032 - accuracy: 0.1023\n",
      "Epoch 170/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 590.7713 - accuracy: 0.1149\n",
      "Epoch 171/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 576.1693 - accuracy: 0.1172\n",
      "Epoch 172/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 604.1222 - accuracy: 0.1108\n",
      "Epoch 173/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 655.7020 - accuracy: 0.1212\n",
      "Epoch 174/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 626.4958 - accuracy: 0.1098\n",
      "Epoch 175/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 620.7040 - accuracy: 0.1093\n",
      "Epoch 176/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 623.1471 - accuracy: 0.1070\n",
      "Epoch 177/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 601.4493 - accuracy: 0.0965\n",
      "Epoch 178/200\n",
      "25440/25440 [==============================] - 80s 3ms/step - loss: 614.8968 - accuracy: 0.1070\n",
      "Epoch 179/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 595.5905 - accuracy: 0.1051\n",
      "Epoch 180/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 657.9029 - accuracy: 0.1045\n",
      "Epoch 181/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 573.0251 - accuracy: 0.1093\n",
      "Epoch 182/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 592.8663 - accuracy: 0.1076\n",
      "Epoch 183/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 581.3306 - accuracy: 0.1030\n",
      "Epoch 184/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 564.9312 - accuracy: 0.1170\n",
      "Epoch 185/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 634.4254 - accuracy: 0.1159\n",
      "Epoch 186/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 587.0579 - accuracy: 0.1216\n",
      "Epoch 187/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 576.2258 - accuracy: 0.1182\n",
      "Epoch 188/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 588.6001 - accuracy: 0.1199\n",
      "Epoch 189/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 573.1421 - accuracy: 0.1201\n",
      "Epoch 190/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 576.7122 - accuracy: 0.1271\n",
      "Epoch 191/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 583.4889 - accuracy: 0.1264\n",
      "Epoch 192/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 577.0911 - accuracy: 0.1260\n",
      "Epoch 193/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 627.0449 - accuracy: 0.1235\n",
      "Epoch 194/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 574.6981 - accuracy: 0.1223\n",
      "Epoch 195/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 611.8286 - accuracy: 0.1183\n",
      "Epoch 196/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 572.8778 - accuracy: 0.1163\n",
      "Epoch 197/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 595.4689 - accuracy: 0.1154\n",
      "Epoch 198/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 620.1027 - accuracy: 0.1155\n",
      "Epoch 199/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 590.1337 - accuracy: 0.1002\n",
      "Epoch 200/200\n",
      "25440/25440 [==============================] - 79s 3ms/step - loss: 621.9506 - accuracy: 0.1095\n"
     ]
    }
   ],
   "source": [
    "#RNN\n",
    "from keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from keras.layers import Activation, Dense\n",
    "\n",
    "model2 = Sequential()\n",
    "model2.add(LSTM(X_train.shape[1], return_sequences=True, input_shape=[X_train.shape[1], 1]))\n",
    "model2.add(LSTM(X_train.shape[1], return_sequences=False))\n",
    "model2.add(Dense(1))\n",
    "model2.compile(optimizer='adam', loss = 'mean_squared_error', metrics=['accuracy'])\n",
    "history = model2.fit(X_train, y_train, batch_size = 1, epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# save the model to disk\n",
    "filename = 'RNN_model_200.sav'\n",
    "pickle.dump(model2, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model from disk\n",
    "loaded_model = pickle.load(open(filename, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89/89 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "pred1 = loaded_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame(pred1)\n",
    "df1.to_csv('pred1.csv', index = False)\n",
    "y_test.to_csv('y_test.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
